{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg2A6wv1nZpI"
      },
      "source": [
        "# Using WordNet in our Experiment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### this code is messy and has inconsistensies. i lost a lot of variables in the process of cleaning up the code, and so some parts may be repetitive/redundant, thanks to chatgpt troubleshooting. it was hard to retrieve the version that i originally worked on"
      ],
      "metadata": {
        "id": "cOVBvJNC2Y6E"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLWY-FEYoO9u",
        "outputId": "73c21003-ae41-4e2a-aeac-432e2884407a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import random\n",
        "assert(nltk.download('wordnet'))\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import wordnet as wn\n",
        "from collections import Counter\n",
        "from datasets import load_dataset\n",
        "import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLXsiWrx-eKu",
        "outputId": "d5b9c601-78f3-4953-d306-b7ea8fa95170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    test: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 4358\n",
            "    })\n",
            "    train: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 1801350\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 3760\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"wikitext\", \"wikitext-103-v1\")\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "-gNm-ix3-_If"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"wikitext\", \"wikitext-103-v1\")\n",
        "with open(\"wikitext_train.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for line in dataset[\"train\"][\"text\"]:\n",
        "        if line.strip():\n",
        "            f.write(line + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "H9MRpUmnFr6t"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"wikitext\", \"wikitext-103-v1\")\n",
        "texts = dataset[\"train\"][\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeVoa8EfI98A",
        "outputId": "df2009ec-c298-461e-9abb-9be4c79c6fb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Separating by Frequency"
      ],
      "metadata": {
        "id": "PoHr0chobYLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freq_counter = Counter()\n",
        "\n",
        "for line in texts:\n",
        "    tokens = line.lower().split()\n",
        "    freq_counter.update(tokens)\n",
        "\n",
        "valid_words = []\n",
        "for word in freq_counter:\n",
        "    if wn.synsets(word):\n",
        "        valid_words.append(word)\n",
        "\n",
        "valid_words_sorted = sorted(valid_words, key=lambda w: freq_counter[w], reverse=True)\n",
        "\n",
        "num_words = len(valid_words_sorted)\n",
        "top_n = int(num_words * 0.10)\n",
        "bottom_n = int(num_words * 0.10)\n",
        "\n",
        "top_10_percent = valid_words_sorted[:top_n]\n",
        "bottom_10_percent = valid_words_sorted[-bottom_n:]\n",
        "\n",
        "print(top_10_percent[:20])\n",
        "print(bottom_10_percent[:20])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMTHFsdqLLBR",
        "outputId": "9851b05f-0644-4501-e086-50a95162d741"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['in', 'a', 'was', 'on', 'as', 'by', 'is', 'at', 'he', 'it', 'were', 'an', 'had', 'be', 'but', 'are', 'first', 'not', 'after', 'one']\n",
            "['thalweg', 'grovelling', 'louisianans', 'muckraker', 'duckboards', 'hangouts', 'caruncle', 'fivesome', 'gyration', 'serranus', 'stayers', 'makins', 'dairyman', 'trundled', 'hypnotherapy', 'sponged', 'scraggly', 'ostracise', 'spokeswomen', 'perplexities']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Separating by Frequency and Polysemy\n",
        "This creates a large list that we manually went through to select our target words."
      ],
      "metadata": {
        "id": "FdaIqtlebgUx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hrZeQqDOAvm",
        "outputId": "407d9952-bf8e-4450-df86-a86da346df7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10% words sorted by number of WordNet synsets (first 20 shown):\n",
            "break            synsets: 75   frequency: 7769   POS: n,v\n",
            "breaks           synsets: 75   frequency: 1866   POS: n,v\n",
            "broken           synsets: 72   frequency: 6022   POS: a,s,v\n",
            "cut              synsets: 70   frequency: 11105  POS: a,n,s,v\n",
            "cuts             synsets: 61   frequency: 1946   POS: n,v\n",
            "broke            synsets: 60   frequency: 7035   POS: s,v\n",
            "breaking         synsets: 60   frequency: 3981   POS: n,v\n",
            "run              synsets: 57   frequency: 22597  POS: n,v\n",
            "runs             synsets: 57   frequency: 15050  POS: n,v\n",
            "cutting          synsets: 54   frequency: 2261   POS: n,s,v\n",
            "made             synsets: 52   frequency: 78666  POS: a,s,v\n",
            "play             synsets: 52   frequency: 29615  POS: n,v\n",
            "making           synsets: 52   frequency: 22462  POS: n,v\n",
            "running          synsets: 52   frequency: 10999  POS: a,n,s,v\n",
            "plays            synsets: 52   frequency: 7018   POS: n,v\n",
            "make             synsets: 51   frequency: 31909  POS: n,v\n",
            "makes            synsets: 51   frequency: 8895   POS: n,v\n",
            "better           synsets: 50   frequency: 13455  POS: a,n,r,s,v\n",
            "giving           synsets: 48   frequency: 8466   POS: n,s,v\n",
            "given            synsets: 47   frequency: 24876  POS: n,s,v\n",
            "Bottom 10% words sorted by number of WordNet synsets (first 20 shown):\n",
            "plaies           synsets: 52   frequency: 3      POS: n,v\n",
            "gos              synsets: 34   frequency: 3      POS: n,v\n",
            "comed            synsets: 21   frequency: 3      POS: v\n",
            "haveing          synsets: 19   frequency: 3      POS: v\n",
            "sticked          synsets: 16   frequency: 3      POS: v\n",
            "heaves           synsets: 15   frequency: 4      POS: n,v\n",
            "burnes           synsets: 15   frequency: 3      POS: v\n",
            "snapes           synsets: 13   frequency: 4      POS: v\n",
            "slops            synsets: 11   frequency: 4      POS: n,v\n",
            "knowed           synsets: 11   frequency: 3      POS: v\n",
            "backes           synsets: 10   frequency: 4      POS: v\n",
            "concords         synsets: 10   frequency: 3      POS: n,v\n",
            "companys         synsets: 10   frequency: 3      POS: n,v\n",
            "weares           synsets: 9    frequency: 4      POS: v\n",
            "remits           synsets: 9    frequency: 4      POS: n,v\n",
            "slacking         synsets: 9    frequency: 3      POS: n,v\n",
            "portes           synsets: 9    frequency: 3      POS: n,v\n",
            "bluest           synsets: 8    frequency: 4      POS: s\n",
            "tenderest        synsets: 8    frequency: 4      POS: a,s\n",
            "scorches         synsets: 8    frequency: 3      POS: n,v\n"
          ]
        }
      ],
      "source": [
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Return a set of POS tags for a word in WordNet.\"\"\"\n",
        "    pos_set = set()\n",
        "    for syn in wn.synsets(word):\n",
        "        pos_set.add(syn.pos())\n",
        "    return ','.join(sorted(pos_set))\n",
        "top_word_info = []\n",
        "for word in top_10_percent:\n",
        "    num_synsets = len(wn.synsets(word))\n",
        "    frequency = freq_counter[word]\n",
        "    pos_tags = get_wordnet_pos(word)\n",
        "    top_word_info.append((word, num_synsets, frequency, pos_tags))\n",
        "\n",
        "bottom_word_info = []\n",
        "for word in bottom_10_percent:\n",
        "    num_synsets = len(wn.synsets(word))\n",
        "    frequency = freq_counter[word]\n",
        "    pos_tags = get_wordnet_pos(word)\n",
        "    bottom_word_info.append((word, num_synsets, frequency, pos_tags))\n",
        "\n",
        "top_sorted_by_synsets = sorted(top_word_info, key=lambda x: x[1], reverse=True)\n",
        "bottom_sorted_by_synsets = sorted(bottom_word_info, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"Top 10% words sorted by number of WordNet synsets (first 20 shown):\")\n",
        "for word, syn_count, freq, pos in top_sorted_by_synsets[:20]:\n",
        "    print(f\"{word:15}  synsets: {syn_count:<3}  frequency: {freq:<5}  POS: {pos}\")\n",
        "\n",
        "print(\"Bottom 10% words sorted by number of WordNet synsets (first 20 shown):\")\n",
        "for word, syn_count, freq, pos in bottom_sorted_by_synsets[:20]:\n",
        "    print(f\"{word:15}  synsets: {syn_count:<3}  frequency: {freq:<5}  POS: {pos}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frequent and Polysemous Words"
      ],
      "metadata": {
        "id": "r2EymQovbPIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wikitext_path = \"wikitext_train.txt\"\n",
        "texts = []\n",
        "\n",
        "with open(wikitext_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            texts.append(line.lower())\n",
        "freq_counter = Counter()\n",
        "for line in texts:\n",
        "    tokens = line.split()\n",
        "    freq_counter.update(tokens)\n",
        "\n",
        "wn_lemmas = set(wn.all_lemma_names())\n",
        "\n",
        "def is_valid_word(token):\n",
        "    if not token:\n",
        "        return False\n",
        "    if token.startswith(\"##\"):\n",
        "        return False\n",
        "    if not token.isalpha():\n",
        "        return False\n",
        "    if token != token.lower():\n",
        "        return False\n",
        "    if len(token) < 3:\n",
        "        return False\n",
        "    if token not in wn_lemmas:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "monosemous_words = []\n",
        "\n",
        "for word, freq in freq_counter.most_common():\n",
        "    if is_valid_word(word):\n",
        "        synsets = wn.synsets(word)\n",
        "        if len(synsets) == 1:\n",
        "            syn = synsets[0]\n",
        "            pos = syn.pos()\n",
        "            pos_map = {'n': 'noun', 'v': 'verb', 'a': 'adjective', 's': 'adjective satellite', 'r': 'adverb'}\n",
        "            readable_pos = pos_map.get(pos, pos)\n",
        "            monosemous_words.append((word, freq, readable_pos))\n",
        "\n",
        "print(f\"Found {len(monosemous_words)} monosemous valid words in Wikitext.\\n\")\n",
        "print(\"Most frequent monosemous words (top 100 shown):\")\n",
        "for word, freq, pos in monosemous_words[:100]:\n",
        "    print(f\"{word:15}  frequency: {freq:<8}  POS: {pos}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLrHWIDPjkB9",
        "outputId": "51b1640e-fba0-4e89-f757-484e0e2b7f8c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 24706 monosemous valid words in Wikitext.\n",
            "\n",
            "Most frequent monosemous words (top 100 shown):\n",
            "but              frequency: 211715    POS: adverb\n",
            "not              frequency: 198856    POS: adverb\n",
            "also             frequency: 184893    POS: adverb\n",
            "who              frequency: 159712    POS: noun\n",
            "while            frequency: 107147    POS: noun\n",
            "both             frequency: 70689     POS: adjective satellite\n",
            "many             frequency: 66193     POS: adjective\n",
            "september        frequency: 45264     POS: noun\n",
            "another          frequency: 44200     POS: adjective satellite\n",
            "october          frequency: 41416     POS: noun\n",
            "june             frequency: 39179     POS: noun\n",
            "july             frequency: 38497     POS: noun\n",
            "november         frequency: 38234     POS: noun\n",
            "april            frequency: 37482     POS: noun\n",
            "york             frequency: 36284     POS: noun\n",
            "december         frequency: 35318     POS: noun\n",
            "january          frequency: 34772     POS: noun\n",
            "within           frequency: 33321     POS: adverb\n",
            "river            frequency: 33032     POS: noun\n",
            "february         frequency: 30753     POS: noun\n",
            "again            frequency: 30644     POS: adverb\n",
            "though           frequency: 30431     POS: adverb\n",
            "england          frequency: 26744     POS: noun\n",
            "highway          frequency: 22802     POS: noun\n",
            "aircraft         frequency: 22764     POS: noun\n",
            "hurricane        frequency: 20273     POS: noun\n",
            "eventually       frequency: 19736     POS: adverb\n",
            "almost           frequency: 16835     POS: adverb\n",
            "soon             frequency: 16675     POS: adverb\n",
            "initially        frequency: 16642     POS: adverb\n",
            "non              frequency: 16497     POS: adverb\n",
            "michael          frequency: 16215     POS: noun\n",
            "either           frequency: 15362     POS: adverb\n",
            "wife             frequency: 15246     POS: noun\n",
            "victory          frequency: 15222     POS: noun\n",
            "robert           frequency: 15095     POS: noun\n",
            "mid              frequency: 14571     POS: adjective satellite\n",
            "successful       frequency: 14051     POS: adjective\n",
            "additional       frequency: 13194     POS: adjective satellite\n",
            "canada           frequency: 13078     POS: noun\n",
            "previously       frequency: 12958     POS: adverb\n",
            "california       frequency: 12757     POS: noun\n",
            "infantry         frequency: 12659     POS: noun\n",
            "germany          frequency: 12220     POS: noun\n",
            "india            frequency: 12190     POS: noun\n",
            "sometimes        frequency: 12171     POS: adverb\n",
            "already          frequency: 11853     POS: adverb\n",
            "usually          frequency: 11748     POS: adverb\n",
            "britain          frequency: 11362     POS: noun\n",
            "might            frequency: 10972     POS: noun\n",
            "percent          frequency: 10904     POS: noun\n",
            "approximately    frequency: 10872     POS: adverb\n",
            "naval            frequency: 10838     POS: adjective\n",
            "daughter         frequency: 10695     POS: noun\n",
            "subsequently     frequency: 10558     POS: adverb\n",
            "museum           frequency: 10312     POS: noun\n",
            "guitar           frequency: 10296     POS: noun\n",
            "billboard        frequency: 9983      POS: noun\n",
            "numerous         frequency: 9847      POS: adjective satellite\n",
            "florida          frequency: 9574      POS: noun\n",
            "texas            frequency: 9439      POS: noun\n",
            "movie            frequency: 9341      POS: noun\n",
            "mary             frequency: 9278      POS: noun\n",
            "valley           frequency: 9253      POS: noun\n",
            "entertainment    frequency: 9224      POS: noun\n",
            "africa           frequency: 9155      POS: noun\n",
            "artist           frequency: 9135      POS: noun\n",
            "respectively     frequency: 9006      POS: adverb\n",
            "prince           frequency: 8612      POS: noun\n",
            "stadium          frequency: 8271      POS: noun\n",
            "dvd              frequency: 8037      POS: noun\n",
            "ultimately       frequency: 7951      POS: adverb\n",
            "mexico           frequency: 7885      POS: noun\n",
            "financial        frequency: 7798      POS: adjective\n",
            "scotland         frequency: 7728      POS: noun\n",
            "airport          frequency: 7677      POS: noun\n",
            "zealand          frequency: 7581      POS: noun\n",
            "subsequent       frequency: 7457      POS: adjective\n",
            "relatively       frequency: 7203      POS: adverb\n",
            "concept          frequency: 7085      POS: noun\n",
            "boston           frequency: 7057      POS: noun\n",
            "alongside        frequency: 7052      POS: adverb\n",
            "historian        frequency: 6982      POS: noun\n",
            "soundtrack       frequency: 6904      POS: noun\n",
            "louis            frequency: 6848      POS: noun\n",
            "mainly           frequency: 6831      POS: adverb\n",
            "italy            frequency: 6724      POS: noun\n",
            "rainfall         frequency: 6490      POS: noun\n",
            "equipment        frequency: 6473      POS: noun\n",
            "hotel            frequency: 6449      POS: noun\n",
            "medal            frequency: 6343      POS: noun\n",
            "stephen          frequency: 6322      POS: noun\n",
            "typically        frequency: 6170      POS: adverb\n",
            "why              frequency: 6122      POS: noun\n",
            "carolina         frequency: 6044      POS: noun\n",
            "frequently       frequency: 5976      POS: adverb\n",
            "tech             frequency: 5960      POS: noun\n",
            "famous           frequency: 5843      POS: adjective satellite\n",
            "newly            frequency: 5769      POS: adverb\n",
            "website          frequency: 5764      POS: noun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Frequent and Polysemous words list\n"
      ],
      "metadata": {
        "id": "U1K0Cl5ae02s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Frequent and Polysemous words list\n",
        "These words were manually selected to account for POS to the best of our ability"
      ],
      "metadata": {
        "id": "p02jzfzCbpCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. break\n",
        "2. cut\n",
        "3. running\n",
        "4. play\n",
        "5. make\n",
        "6. better\n",
        "7. light\n",
        "8. falls\n",
        "9. clear\n",
        "10. open\n"
      ],
      "metadata": {
        "id": "Gpvf2FLmbu9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confirming their # of similar words\n"
      ],
      "metadata": {
        "id": "i71j5GNydwDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_polysemy = ['break', 'cut', 'running', 'play', 'make', 'better', 'light', 'falls', 'clear', 'open']\n",
        "vocab = set()\n",
        "for line in texts:\n",
        "    tokens = line.lower().split()\n",
        "    for token in tokens:\n",
        "        vocab.add(token)\n",
        "\n",
        "vocab = list(vocab)\n",
        "\n",
        "def get_similar_words(word, num_words=10):\n",
        "    related = set()\n",
        "    synsets = wn.synsets(word)\n",
        "    for syn in synsets:\n",
        "        for lemma in syn.lemmas():\n",
        "            if lemma.name().lower() != word:\n",
        "                related.add(lemma.name().lower())\n",
        "        for hyper in syn.hypernyms() + syn.hyponyms():\n",
        "            for lemma in hyper.lemmas():\n",
        "                related.add(lemma.name().lower())\n",
        "    related = list(related)\n",
        "    random.shuffle(related)\n",
        "    return related[:num_words]\n",
        "\n",
        "def get_dissimilar_words(word, num_words=10):\n",
        "    choices = set()\n",
        "    while len(choices) < num_words:\n",
        "        candidate = random.choice(vocab)\n",
        "        if candidate != word:\n",
        "            choices.add(candidate)\n",
        "    return list(choices)\n",
        "\n",
        "word_dict = {}\n",
        "\n",
        "for word in final_polysemy:\n",
        "    word_dict[word] = {}\n",
        "    word_dict[word]['similar_words'] = get_similar_words(word, 10)\n",
        "    word_dict[word]['dissimilar_words'] = get_dissimilar_words(word, 10)\n",
        "\n",
        "for w in final_polysemy:\n",
        "    print(f\"\\n{w}:\")\n",
        "    print(\"  similar_words:\", word_dict[w]['similar_words'])\n",
        "    print(\"  dissimilar_words:\", word_dict[w]['dissimilar_words'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFGDEfLId6lX",
        "outputId": "d4e69d9c-1314-46ec-fb34-922b6214f5b5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "break:\n",
            "  similar_words: ['pause', 'interval', 'give_the_bounce', 'disclose', 'shot', 'trip_the_light_fantastic', 'break_away', 'break_out', 'misfunction', 'falling_out']\n",
            "  dissimilar_words: ['denisof', 'endzone', 'hayter', 'fame', 'rubbing', 'eishima', 'smashers', 'præn', 'artepiazza', 'romema']\n",
            "\n",
            "cut:\n",
            "  similar_words: ['ruffle', 'knap', 'curve', 'weaken', 'plane', 'grow', 'dissection', 'abridge', 'flip', 'cut_down']\n",
            "  dissimilar_words: ['elantra', 'trireme', 'piggyback', 'ev', 'councilwoman', 'corneal', 'cores', 'velshi', 'weepingwillow17', 'kingsglaive']\n",
            "\n",
            "running:\n",
            "  similar_words: ['football_play', 'rabbit', 'propagate', 'carry_through', 'fulfill', 'treat', 'swirl', 'filter', 'spread_out', 'go_deep']\n",
            "  dissimilar_words: ['383b', 'quinquennial', 'etherians', 'itching', 'resemblant', 'valise', 'vangshylla', 'onecommunity', 'firebenders', 'bookwalter']\n",
            "\n",
            "play:\n",
            "  similar_words: ['backstop', 'slackness', 'flirtation', 'symphonise', 'walk', 'hole', 'wit', 'morality_play', 'recapitulate', 'utilisation']\n",
            "  dissimilar_words: ['stanchions', 'basile', 'betatron', 'paleogene', 'orpik', 'antanimena', 'unlawfully', 'congregationalism', 'parke', 'nour']\n",
            "\n",
            "make:\n",
            "  similar_words: ['perform', 'breed', 'ground', 'develop', 'output', 'customise', 'ready', 'persuade', 'grow', 'give_rise']\n",
            "  dissimilar_words: ['unfriendly', 'spellcasters', 'mulhern', 'komura', 'subcarbonate', 'gtd', 'pujo', 'money', 'respiration', 'jat']\n",
            "\n",
            "better:\n",
            "  similar_words: ['beautify', 'practiced', 'unspoilt', 'build', 'aid', 'convalesce', 'surge', 'proficient', 'sound', 'full']\n",
            "  dissimilar_words: ['ellen', 'awrs', 'lifesong', 'crayfish', 'interrelationship', 'legio', 'elenin', 'bisbee', 'carolinas', 'kaplow']\n",
            "\n",
            "light:\n",
            "  similar_words: ['luminosity', 'device', 'headlight', 'beam_of_light', 'illume', 'actinic_ray', 'searchlight', 'face', 'enkindle', 'ethics']\n",
            "  dissimilar_words: ['pasqua', '1691', 'fma', 'emlen', 'tigernach', 'blixen', 'thomas', 'greenback', 'tingen', 'skilbeck']\n",
            "\n",
            "falls:\n",
            "  similar_words: ['fall', 'resign', 'lessen', 'get', 'slump', 'decrement', 'swoop', 'rappel', 'nightfall', 'cataract']\n",
            "  dissimilar_words: ['reverie', 'tonokura', 'bábí', 'collyhurst', 'divert', 'lien', 'znp', 'nectoux', 'sembach', 'sobbed']\n",
            "\n",
            "clear:\n",
            "  similar_words: ['commission', 'create', 'pull_in', 'brighten', 'empty', 'permit', 'countenance', 'pay', 'unclouded', 'net']\n",
            "  dissimilar_words: ['hkn', 'drenović', 'triakidae', 'haliaetus', 'bernes', 'rnvr', 'casshern', 'comforted', 'lillestrøm', 'extramural']\n",
            "\n",
            "open:\n",
            "  similar_words: ['area', 'found', 'grass', 'afford', 'unfasten', 'heart-to-heart', 'outside', 'divaricate', 'undo', 'display']\n",
            "  dissimilar_words: ['urbanity', 'scaled', 'diyar', 'rodillo', 'mindy', 'countercharged', 'keeravani', 'krum', 'proscription', 'farms']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confirm if in Bert Vocab:"
      ],
      "metadata": {
        "id": "elqQcZ8KboG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_vocab_path = \"vocab.txt\"\n",
        "\n",
        "bert_vocab = set()\n",
        "with open(bert_vocab_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        token = line.strip()\n",
        "        if token:\n",
        "            bert_vocab.add(token)"
      ],
      "metadata": {
        "id": "yxxTVmlNeN8j"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in poly_freq:\n",
        "  if word in bert_vocab:\n",
        "    print(f\"{word} is in the BERT vocab.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD1__0Ccd9zz",
        "outputId": "25a84ca6-eaa8-413b-d34b-3eba0f6d7a2a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "break is in the BERT vocab.\n",
            "cut is in the BERT vocab.\n",
            "running is in the BERT vocab.\n",
            "play is in the BERT vocab.\n",
            "make is in the BERT vocab.\n",
            "better is in the BERT vocab.\n",
            "light is in the BERT vocab.\n",
            "falls is in the BERT vocab.\n",
            "clear is in the BERT vocab.\n",
            "open is in the BERT vocab.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Similar Word Finder\n",
        "Used to manually check each word's similar word number before determining if it is added to the list or not."
      ],
      "metadata": {
        "id": "rVhagfMcBiL6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGKN3_k0-kZw",
        "outputId": "a59592a4-570f-463d-d226-6098aa552cc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 11338 BERT vocab words.\n",
            "Enter a word: open\n",
            "Number of WordNet-based similar words in BERT vocab for 'open': 34\n",
            "Similar words: ['gap', 'outside', 'found', 'capable', 'launch', 'yield', 'jimmy', 'opened', 'subject', 'start', 'breach', 'country', 'lance', 'go', 'candid', 'prize', 'loose', 'clear', 'turn', 'surface', 'area', 'establish', 'grass', 'exposed', 'exhibit', 'spread', 'butterfly', 'move', 'tournament', 'afford', 'give', 'overt', 'exterior', 'display']\n"
          ]
        }
      ],
      "source": [
        "vocab_file = \"vocab.txt\"\n",
        "bert_vocab = set()\n",
        "\n",
        "with open(vocab_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        token = line.strip()\n",
        "        if token.isalpha() and token.islower():\n",
        "            bert_vocab.add(token)\n",
        "\n",
        "print(f\"Loaded {len(bert_vocab)} BERT vocab words.\")\n",
        "\n",
        "def wordnet_similar_in_bert(word):\n",
        "    word_lower = word.lower()\n",
        "    related = set()\n",
        "\n",
        "    for syn in wn.synsets(word_lower):\n",
        "        for lemma in syn.lemmas():\n",
        "            related.add(lemma.name().lower())\n",
        "        for hyper in syn.hypernyms():\n",
        "            for lemma in hyper.lemmas():\n",
        "                related.add(lemma.name().lower())\n",
        "        for hypo in syn.hyponyms():\n",
        "            for lemma in hypo.lemmas():\n",
        "                related.add(lemma.name().lower())\n",
        "\n",
        "    related.discard(word_lower)\n",
        "    filtered = [w for w in related if w in bert_vocab]\n",
        "\n",
        "    return filtered\n",
        "\n",
        "input_word = input(\"Enter a word: \").strip().lower()\n",
        "similar_words = wordnet_similar_in_bert(input_word)\n",
        "\n",
        "print(f\"Number of WordNet-based similar words in BERT vocab for '{input_word}': {len(similar_words)}\")\n",
        "print(\"Similar words:\", similar_words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Infrequent and Polysemous words"
      ],
      "metadata": {
        "id": "QkOEyOxuBYQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Infrequent and Polysemous words list"
      ],
      "metadata": {
        "id": "TtZ2p67nprmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wikitext_path = \"wikitext_train.txt\"\n",
        "\n",
        "with open(wikitext_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            texts.append(line.lower())\n",
        "freq_counter = Counter()\n",
        "for line in texts:\n",
        "    tokens = line.split()\n",
        "    freq_counter.update(tokens)\n",
        "\n",
        "wn_lemmas = set(wn.all_lemma_names())\n",
        "\n",
        "def is_valid_word(token):\n",
        "    if not token:\n",
        "        return False\n",
        "    if token.startswith(\"##\"):\n",
        "        return False\n",
        "    if not token.isalpha():\n",
        "        return False\n",
        "    if token != token.lower():\n",
        "        return False\n",
        "    if len(token) < 3:\n",
        "        return False\n",
        "    if token not in wn_lemmas:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "monosemous_words = []\n",
        "polysemous_words = []\n",
        "\n",
        "for word, freq in freq_counter.most_common():\n",
        "    if is_valid_word(word):\n",
        "        synsets = wn.synsets(word)\n",
        "        if len(synsets) == 1:\n",
        "            syn = synsets[0]\n",
        "            pos = syn.pos()\n",
        "            pos_map = {'n': 'noun', 'v': 'verb', 'a': 'adjective', 's': 'adjective satellite', 'r': 'adverb'}\n",
        "            readable_pos = pos_map.get(pos, pos)\n",
        "            monosemous_words.append((word, freq, readable_pos))\n",
        "        elif len(synsets) > 1:\n",
        "            polysemous_words.append((word, freq, len(synsets)))\n",
        "\n",
        "print(f\"Found {len(monosemous_words)} monosemous and {len(polysemous_words)} polysemous valid words in Wikitext.\\n\")\n",
        "\n",
        "print(\"Top 100 most frequent monosemous words:\")\n",
        "for word, freq, pos in monosemous_words[:100]:\n",
        "    print(f\"{word:15}  frequency: {freq:<8}  POS: {pos}\")\n",
        "\n",
        "print(\"\\nTop 100 polysemous words (by frequency):\")\n",
        "for word, freq, sense_count in polysemous_words[:100]:\n",
        "    print(f\"{word:15}  frequency: {freq:<8}  senses: {sense_count}\")\n",
        "\n",
        "infrequent_words = [w for w in polysemous_words if w[1] <= 2]\n",
        "print(f\"\\nFound {len(infrequent_words)} infrequent (freq ≤ 2) polysemous words.\")\n",
        "for word, freq, sense_count in infrequent_words[:50]:\n",
        "    print(f\"{word:15}  frequency: {freq:<8}  senses: {sense_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g41eifjdpU8Q",
        "outputId": "f92bf65c-8afe-4f48-dd22-6a69bb0ad3f5"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 24706 monosemous and 22997 polysemous valid words in Wikitext.\n",
            "\n",
            "Top 100 most frequent monosemous words:\n",
            "but              frequency: 423430    POS: adverb\n",
            "not              frequency: 397712    POS: adverb\n",
            "also             frequency: 369786    POS: adverb\n",
            "who              frequency: 319424    POS: noun\n",
            "while            frequency: 214294    POS: noun\n",
            "both             frequency: 141378    POS: adjective satellite\n",
            "many             frequency: 132386    POS: adjective\n",
            "september        frequency: 90528     POS: noun\n",
            "another          frequency: 88400     POS: adjective satellite\n",
            "october          frequency: 82832     POS: noun\n",
            "june             frequency: 78358     POS: noun\n",
            "july             frequency: 76994     POS: noun\n",
            "november         frequency: 76468     POS: noun\n",
            "april            frequency: 74964     POS: noun\n",
            "york             frequency: 72568     POS: noun\n",
            "december         frequency: 70636     POS: noun\n",
            "january          frequency: 69544     POS: noun\n",
            "within           frequency: 66642     POS: adverb\n",
            "river            frequency: 66064     POS: noun\n",
            "february         frequency: 61506     POS: noun\n",
            "again            frequency: 61288     POS: adverb\n",
            "though           frequency: 60862     POS: adverb\n",
            "england          frequency: 53488     POS: noun\n",
            "highway          frequency: 45604     POS: noun\n",
            "aircraft         frequency: 45528     POS: noun\n",
            "hurricane        frequency: 40546     POS: noun\n",
            "eventually       frequency: 39472     POS: adverb\n",
            "almost           frequency: 33670     POS: adverb\n",
            "soon             frequency: 33350     POS: adverb\n",
            "initially        frequency: 33284     POS: adverb\n",
            "non              frequency: 32994     POS: adverb\n",
            "michael          frequency: 32430     POS: noun\n",
            "either           frequency: 30724     POS: adverb\n",
            "wife             frequency: 30492     POS: noun\n",
            "victory          frequency: 30444     POS: noun\n",
            "robert           frequency: 30190     POS: noun\n",
            "mid              frequency: 29142     POS: adjective satellite\n",
            "successful       frequency: 28102     POS: adjective\n",
            "additional       frequency: 26388     POS: adjective satellite\n",
            "canada           frequency: 26156     POS: noun\n",
            "previously       frequency: 25916     POS: adverb\n",
            "california       frequency: 25514     POS: noun\n",
            "infantry         frequency: 25318     POS: noun\n",
            "germany          frequency: 24440     POS: noun\n",
            "india            frequency: 24380     POS: noun\n",
            "sometimes        frequency: 24342     POS: adverb\n",
            "already          frequency: 23706     POS: adverb\n",
            "usually          frequency: 23496     POS: adverb\n",
            "britain          frequency: 22724     POS: noun\n",
            "might            frequency: 21944     POS: noun\n",
            "percent          frequency: 21808     POS: noun\n",
            "approximately    frequency: 21744     POS: adverb\n",
            "naval            frequency: 21676     POS: adjective\n",
            "daughter         frequency: 21390     POS: noun\n",
            "subsequently     frequency: 21116     POS: adverb\n",
            "museum           frequency: 20624     POS: noun\n",
            "guitar           frequency: 20592     POS: noun\n",
            "billboard        frequency: 19966     POS: noun\n",
            "numerous         frequency: 19694     POS: adjective satellite\n",
            "florida          frequency: 19148     POS: noun\n",
            "texas            frequency: 18878     POS: noun\n",
            "movie            frequency: 18682     POS: noun\n",
            "mary             frequency: 18556     POS: noun\n",
            "valley           frequency: 18506     POS: noun\n",
            "entertainment    frequency: 18448     POS: noun\n",
            "africa           frequency: 18310     POS: noun\n",
            "artist           frequency: 18270     POS: noun\n",
            "respectively     frequency: 18012     POS: adverb\n",
            "prince           frequency: 17224     POS: noun\n",
            "stadium          frequency: 16542     POS: noun\n",
            "dvd              frequency: 16074     POS: noun\n",
            "ultimately       frequency: 15902     POS: adverb\n",
            "mexico           frequency: 15770     POS: noun\n",
            "financial        frequency: 15596     POS: adjective\n",
            "scotland         frequency: 15456     POS: noun\n",
            "airport          frequency: 15354     POS: noun\n",
            "zealand          frequency: 15162     POS: noun\n",
            "subsequent       frequency: 14914     POS: adjective\n",
            "relatively       frequency: 14406     POS: adverb\n",
            "concept          frequency: 14170     POS: noun\n",
            "boston           frequency: 14114     POS: noun\n",
            "alongside        frequency: 14104     POS: adverb\n",
            "historian        frequency: 13964     POS: noun\n",
            "soundtrack       frequency: 13808     POS: noun\n",
            "louis            frequency: 13696     POS: noun\n",
            "mainly           frequency: 13662     POS: adverb\n",
            "italy            frequency: 13448     POS: noun\n",
            "rainfall         frequency: 12980     POS: noun\n",
            "equipment        frequency: 12946     POS: noun\n",
            "hotel            frequency: 12898     POS: noun\n",
            "medal            frequency: 12686     POS: noun\n",
            "stephen          frequency: 12644     POS: noun\n",
            "typically        frequency: 12340     POS: adverb\n",
            "why              frequency: 12244     POS: noun\n",
            "carolina         frequency: 12088     POS: noun\n",
            "frequently       frequency: 11952     POS: adverb\n",
            "tech             frequency: 11920     POS: noun\n",
            "famous           frequency: 11686     POS: adjective satellite\n",
            "newly            frequency: 11538     POS: adverb\n",
            "website          frequency: 11528     POS: noun\n",
            "\n",
            "Top 100 polysemous words (by frequency):\n",
            "are              frequency: 410224    senses: 14\n",
            "first            frequency: 407788    senses: 16\n",
            "after            frequency: 383476    senses: 3\n",
            "one              frequency: 378498    senses: 9\n",
            "two              frequency: 341772    senses: 3\n",
            "have             frequency: 328908    senses: 20\n",
            "new              frequency: 306048    senses: 12\n",
            "time             frequency: 264716    senses: 15\n",
            "other            frequency: 257308    senses: 4\n",
            "all              frequency: 242448    senses: 3\n",
            "more             frequency: 229874    senses: 5\n",
            "over             frequency: 211902    senses: 7\n",
            "game             frequency: 198448    senses: 14\n",
            "only             frequency: 196960    senses: 9\n",
            "later            frequency: 196800    senses: 12\n",
            "most             frequency: 191388    senses: 5\n",
            "three            frequency: 189138    senses: 3\n",
            "about            frequency: 188344    senses: 8\n",
            "out              frequency: 187538    senses: 17\n",
            "between          frequency: 185950    senses: 2\n",
            "there            frequency: 181318    senses: 4\n",
            "some             frequency: 170900    senses: 5\n",
            "film             frequency: 168606    senses: 7\n",
            "may              frequency: 167072    senses: 2\n",
            "before           frequency: 161674    senses: 2\n",
            "year             frequency: 160502    senses: 4\n",
            "made             frequency: 157332    senses: 52\n",
            "such             frequency: 155112    senses: 2\n",
            "second           frequency: 152848    senses: 15\n",
            "season           frequency: 152790    senses: 6\n",
            "years            frequency: 148042    senses: 7\n",
            "world            frequency: 147962    senses: 9\n",
            "war              frequency: 147584    senses: 5\n",
            "however          frequency: 140320    senses: 4\n",
            "then             frequency: 140274    senses: 5\n",
            "used             frequency: 139698    senses: 9\n",
            "being            frequency: 138304    senses: 15\n",
            "through          frequency: 138288    senses: 7\n",
            "song             frequency: 137786    senses: 6\n",
            "series           frequency: 136268    senses: 7\n",
            "album            frequency: 133176    senses: 2\n",
            "team             frequency: 129540    senses: 3\n",
            "city             frequency: 129014    senses: 3\n",
            "part             frequency: 128188    senses: 18\n",
            "north            frequency: 128072    senses: 9\n",
            "number           frequency: 127514    senses: 17\n",
            "united           frequency: 126846    senses: 8\n",
            "can              frequency: 126484    senses: 8\n",
            "several          frequency: 126472    senses: 3\n",
            "well             frequency: 125960    senses: 22\n",
            "four             frequency: 125912    senses: 3\n",
            "early            frequency: 123718    senses: 9\n",
            "state            frequency: 122790    senses: 11\n",
            "under            frequency: 122550    senses: 10\n",
            "south            frequency: 118666    senses: 7\n",
            "music            frequency: 118248    senses: 5\n",
            "day              frequency: 116602    senses: 10\n",
            "episode          frequency: 115044    senses: 4\n",
            "said             frequency: 113750    senses: 12\n",
            "following        frequency: 113556    senses: 30\n",
            "known            frequency: 109606    senses: 12\n",
            "american         frequency: 109560    senses: 5\n",
            "work             frequency: 106502    senses: 34\n",
            "like             frequency: 101740    senses: 11\n",
            "high             frequency: 99320     senses: 18\n",
            "people           frequency: 99094     senses: 6\n",
            "end              frequency: 97728     senses: 18\n",
            "million          frequency: 95704     senses: 3\n",
            "british          frequency: 95050     senses: 2\n",
            "around           frequency: 94014     senses: 10\n",
            "long             frequency: 92848     senses: 12\n",
            "each             frequency: 92466     senses: 2\n",
            "national         frequency: 92432     senses: 8\n",
            "life             frequency: 91500     senses: 14\n",
            "best             frequency: 91264     senses: 43\n",
            "found            frequency: 91208     senses: 21\n",
            "west             frequency: 89964     senses: 10\n",
            "same             frequency: 89932     senses: 6\n",
            "back             frequency: 88864     senses: 28\n",
            "along            frequency: 88516     senses: 5\n",
            "five             frequency: 88148     senses: 4\n",
            "show             frequency: 87172     senses: 16\n",
            "use              frequency: 86004     senses: 13\n",
            "any              frequency: 85490     senses: 2\n",
            "area             frequency: 85172     senses: 6\n",
            "final            frequency: 84876     senses: 5\n",
            "group            frequency: 84830     senses: 5\n",
            "off              frequency: 84426     senses: 9\n",
            "august           frequency: 83790     senses: 3\n",
            "century          frequency: 83534     senses: 2\n",
            "received         frequency: 83370     senses: 15\n",
            "john             frequency: 82520     senses: 5\n",
            "school           frequency: 81620     senses: 10\n",
            "due              frequency: 80702     senses: 7\n",
            "line             frequency: 79544     senses: 36\n",
            "will             frequency: 79540     senses: 6\n",
            "government       frequency: 79030     senses: 4\n",
            "east             frequency: 78114     senses: 7\n",
            "single           frequency: 77662     senses: 10\n",
            "system           frequency: 77624     senses: 9\n",
            "\n",
            "Found 0 infrequent (freq ≤ 2) polysemous words.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After using the Similar Word Finder, we searched for words that did fit the criteria."
      ],
      "metadata": {
        "id": "51Sf2fAKp2g3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksnUQWif_s5O",
        "outputId": "c8d74174-4261-41d3-fd53-680ba730edce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 998 bottom 10% frequency words.\n",
            "\n",
            "Top polysemous, infrequent words with ≥10 similar words:\n",
            "\n",
            "Word: comed\n",
            "  # Synsets: 21\n",
            "  # Similar (in vocab): 45\n",
            "  Similar words: ['settle', 'rise', 'be', 'pass', 'extend', 'follow', 'shore', 'become', 'number', 'aggregate']\n",
            "\n",
            "Word: bes\n",
            "  # Synsets: 14\n",
            "  # Similar (in vocab): 127\n",
            "  Similar words: ['promise', 'remain', 'hold', 'cost', 'lie', 'flow', 'live', 'swim', 'consist', 'buzz']\n",
            "\n",
            "Word: hitch\n",
            "  # Synsets: 12\n",
            "  # Similar (in vocab): 18\n",
            "  Similar words: ['ride', 'check', 'rub', 'buck', 'move', 'tie', 'tour', 'walk', 'halt', 'connection']\n",
            "\n",
            "Word: ses\n",
            "  # Synsets: 8\n",
            "  # Similar (in vocab): 11\n",
            "  Similar words: ['sec', 's', 'south', 'southward', 'point', 'letter', 'southeast', 'sulfur', 'element', 'se']\n",
            "\n",
            "Word: ply\n",
            "  # Synsets: 8\n",
            "  # Similar (in vocab): 31\n",
            "  Similar words: ['accommodate', 'employ', 'treat', 'bed', 'dish', 'fill', 'meet', 'power', 'travel', 'join']\n",
            "\n",
            "Word: vamp\n",
            "  # Synsets: 7\n",
            "  # Similar (in vocab): 14\n",
            "  Similar words: ['butterfly', 'manufacture', 'support', 'romance', 'patch', 'invent', 'restore', 'woman', 'repair', 'doctor']\n",
            "\n",
            "Word: cant\n",
            "  # Synsets: 6\n",
            "  # Similar (in vocab): 10\n",
            "  Similar words: ['edge', 'slant', 'talk', 'bank', 'move', 'pitch', 'cock', 'slope', 'side', 'talking']\n",
            "\n",
            "Word: cons\n",
            "  # Synsets: 5\n",
            "  # Similar (in vocab): 12\n",
            "  Similar words: ['con', 'rook', 'statement', 'rig', 'prisoner', 'learn', 'study', 'short', 'captive', 'sting']\n",
            "\n",
            "Word: middles\n",
            "  # Synsets: 5\n",
            "  # Similar (in vocab): 22\n",
            "  Similar words: ['division', 'midfield', 'deep', 'hub', 'place', 'area', 'country', 'section', 'lay', 'middle']\n",
            "\n",
            "Word: mend\n",
            "  # Synsets: 4\n",
            "  # Similar (in vocab): 18\n",
            "  Similar words: ['care', 'reconstruction', 'improvement', 'improve', 'vamp', 'maintenance', 'sole', 'fill', 'patch', 'point']\n",
            "\n",
            "Word: spiel\n",
            "  # Synsets: 3\n",
            "  # Similar (in vocab): 11\n",
            "  Similar words: ['jazz', 'play', 'riff', 'talk', 'channel', 'speak', 'repeat', 'replay', 'rag', 'tongue']\n",
            "\n",
            "Word: pent\n",
            "  # Synsets: 2\n",
            "  # Similar (in vocab): 11\n",
            "  Similar words: ['profile', 'adopt', 'draw', 'draft', 'lyric', 'script', 'verse', 'reference', 'author', 'write']\n",
            "\n",
            "Word: aver\n",
            "  # Synsets: 2\n",
            "  # Similar (in vocab): 10\n",
            "  Similar words: ['maintain', 'assert', 'hold', 'claim', 'tell', 'say', 'swan', 'take', 'protest', 'declare']\n",
            "\n",
            "Word: slav\n",
            "  # Synsets: 2\n",
            "  # Similar (in vocab): 10\n",
            "  Similar words: ['croatian', 'mortal', 'soul', 'individual', 'person', 'serb', 'croat', 'serbian', 'someone', 'somebody']\n",
            "\n",
            "Word: pic\n",
            "  # Synsets: 2\n",
            "  # Similar (in vocab): 18\n",
            "  Similar words: ['shot', 'picture', 'production', 'frame', 'documentary', 'still', 'movie', 'product', 'photo', 'print']\n",
            "\n",
            "Word: eff\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 11\n",
            "  Similar words: ['jazz', 'bed', 'have', 'love', 'take', 'couple', 'fuck', 'know', 'bang', 'pair']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vocab_file = \"vocab.txt\"\n",
        "bert_vocab = set()\n",
        "\n",
        "with open(vocab_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        token = line.strip()\n",
        "        if token.isalpha() and token.islower():\n",
        "            bert_vocab.add(token)\n",
        "\n",
        "freq_counter = Counter()\n",
        "for line in texts:\n",
        "    tokens = line.split()\n",
        "    for token in tokens:\n",
        "        token_lower = token.lower()\n",
        "        if token_lower.isalpha() and token_lower in bert_vocab:\n",
        "            freq_counter[token_lower] += 1\n",
        "\n",
        "def get_wordnet_similar_in_bert(word):\n",
        "    \"\"\"Return WordNet-based similar words that exist in BERT vocab.\"\"\"\n",
        "    related = set()\n",
        "    for syn in wn.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            related.add(lemma.name().lower())\n",
        "        for hyper in syn.hypernyms():\n",
        "            for lemma in hyper.lemmas():\n",
        "                related.add(lemma.name().lower())\n",
        "        for hypo in syn.hyponyms():\n",
        "            for lemma in hypo.lemmas():\n",
        "                related.add(lemma.name().lower())\n",
        "    related.discard(word)\n",
        "    return [w for w in related if w in bert_vocab]\n",
        "\n",
        "def get_num_synsets(word):\n",
        "    \"\"\"Return number of WordNet senses.\"\"\"\n",
        "    return len(wn.synsets(word))\n",
        "\n",
        "words_in_vocab = [w for w in bert_vocab if w in freq_counter]\n",
        "if not words_in_vocab:\n",
        "    raise ValueError(\"No BERT vocab words found in dataset!\")\n",
        "\n",
        "frequencies = [freq_counter[w] for w in words_in_vocab]\n",
        "frequencies.sort()\n",
        "threshold = frequencies[int(0.1 * len(frequencies))]\n",
        "bottom_words = [w for w in words_in_vocab if freq_counter[w] <= threshold]\n",
        "\n",
        "print(f\"Found {len(bottom_words)} bottom 10% frequency words.\")\n",
        "\n",
        "candidates = []\n",
        "for word in bottom_words:\n",
        "    similar = get_wordnet_similar_in_bert(word)\n",
        "    if len(similar) >= 10:\n",
        "        candidates.append({\n",
        "            \"word\": word,\n",
        "            \"num_synsets\": get_num_synsets(word),\n",
        "            \"num_similar\": len(similar),\n",
        "            \"similar_words\": similar[:10]\n",
        "        })\n",
        "\n",
        "candidates_sorted = sorted(candidates, key=lambda x: x[\"num_synsets\"], reverse=True)\n",
        "\n",
        "print(\"\\nTop polysemous, infrequent words with ≥10 similar words:\\n\")\n",
        "for entry in candidates_sorted[:20]:\n",
        "    print(f\"Word: {entry['word']}\")\n",
        "    print(f\"  # Synsets: {entry['num_synsets']}\")\n",
        "    print(f\"  # Similar (in vocab): {entry['num_similar']}\")\n",
        "    print(f\"  Similar words: {entry['similar_words']}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Infrequent Polysemous words list\n",
        "From the list above, the following words were chosen:\n",
        "\n",
        "1.   ply\n",
        "2.   vamp\n",
        "3. cant\n",
        "4. cons\n",
        "4. mend\n",
        "5. spiel\n",
        "6. hitch\n",
        "7. middles\n",
        "8. crams\n",
        "10. weares\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Jjw2oIRJQaL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confirm if in Bert Vocab"
      ],
      "metadata": {
        "id": "pDPj4TFGnB0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poly_infreq = [\"ply\", \"vamp\", \"cant\", \"weares\", \"crams\",\n",
        "               \"cons\", \"mend\", \"spiel\", \"hitch\", \"middles\"]"
      ],
      "metadata": {
        "id": "lzIiYaQCnJLX"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in poly_infreq:\n",
        "  if word in bert_vocab:\n",
        "    print(f\"{word} is in the BERT vocab.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOlfSCgqnGym",
        "outputId": "deb74984-ffa2-4965-eec4-3ac6ba6e8e8a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ply is in the BERT vocab.\n",
            "vamp is in the BERT vocab.\n",
            "cant is in the BERT vocab.\n",
            "cons is in the BERT vocab.\n",
            "mend is in the BERT vocab.\n",
            "spiel is in the BERT vocab.\n",
            "hitch is in the BERT vocab.\n",
            "middles is in the BERT vocab.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frequent and Monosemous Words"
      ],
      "metadata": {
        "id": "mglMt-FbBUJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Frequent and Monosemous words list"
      ],
      "metadata": {
        "id": "5JW4hz4zqPwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wikitext_path = \"wikitext_train.txt\"\n",
        "texts = []\n",
        "\n",
        "with open(wikitext_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            texts.append(line.lower())\n",
        "\n",
        "freq_counter = Counter()\n",
        "for line in texts:\n",
        "    tokens = line.split()\n",
        "    freq_counter.update(tokens)\n",
        "\n",
        "wn_lemmas = set(wn.all_lemma_names())\n",
        "\n",
        "def is_valid_word(token):\n",
        "    if not token:\n",
        "        return False\n",
        "    if token.startswith(\"##\"):\n",
        "        return False\n",
        "    if not token.isalpha():\n",
        "        return False\n",
        "    if token != token.lower():\n",
        "        return False\n",
        "    if len(token) < 3:\n",
        "        return False\n",
        "    if token not in wn_lemmas:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "monosemous_words = []\n",
        "freq_threshold = 50\n",
        "\n",
        "for word, freq in freq_counter.most_common():\n",
        "    if freq < freq_threshold:\n",
        "        break\n",
        "    if is_valid_word(word):\n",
        "        synsets = wn.synsets(word)\n",
        "        if len(synsets) == 1:\n",
        "            syn = synsets[0]\n",
        "            pos = syn.pos()\n",
        "            pos_map = {\n",
        "                'n': 'noun',\n",
        "                'v': 'verb',\n",
        "                'a': 'adjective',\n",
        "                's': 'adjective satellite',\n",
        "                'r': 'adverb'\n",
        "            }\n",
        "            readable_pos = pos_map.get(pos, pos)\n",
        "            monosemous_words.append((word, freq, readable_pos))\n",
        "\n",
        "print(f\"Found {len(monosemous_words)} frequent (freq ≥ {freq_threshold}) monosemous valid words in Wikitext.\\n\")\n",
        "print(\"Most frequent monosemous words:\")\n",
        "for word, freq, pos in monosemous_words[:100]:\n",
        "    print(f\"{word:15}  frequency: {freq:<8}  POS: {pos}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwonZNL-qS-e",
        "outputId": "44683088-38a5-4d3b-ea73-1639d8585ba1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8534 frequent (freq ≥ 50) monosemous valid words in Wikitext.\n",
            "\n",
            "Most frequent monosemous words:\n",
            "but              frequency: 211715    POS: adverb\n",
            "not              frequency: 198856    POS: adverb\n",
            "also             frequency: 184893    POS: adverb\n",
            "who              frequency: 159712    POS: noun\n",
            "while            frequency: 107147    POS: noun\n",
            "both             frequency: 70689     POS: adjective satellite\n",
            "many             frequency: 66193     POS: adjective\n",
            "september        frequency: 45264     POS: noun\n",
            "another          frequency: 44200     POS: adjective satellite\n",
            "october          frequency: 41416     POS: noun\n",
            "june             frequency: 39179     POS: noun\n",
            "july             frequency: 38497     POS: noun\n",
            "november         frequency: 38234     POS: noun\n",
            "april            frequency: 37482     POS: noun\n",
            "york             frequency: 36284     POS: noun\n",
            "december         frequency: 35318     POS: noun\n",
            "january          frequency: 34772     POS: noun\n",
            "within           frequency: 33321     POS: adverb\n",
            "river            frequency: 33032     POS: noun\n",
            "february         frequency: 30753     POS: noun\n",
            "again            frequency: 30644     POS: adverb\n",
            "though           frequency: 30431     POS: adverb\n",
            "england          frequency: 26744     POS: noun\n",
            "highway          frequency: 22802     POS: noun\n",
            "aircraft         frequency: 22764     POS: noun\n",
            "hurricane        frequency: 20273     POS: noun\n",
            "eventually       frequency: 19736     POS: adverb\n",
            "almost           frequency: 16835     POS: adverb\n",
            "soon             frequency: 16675     POS: adverb\n",
            "initially        frequency: 16642     POS: adverb\n",
            "non              frequency: 16497     POS: adverb\n",
            "michael          frequency: 16215     POS: noun\n",
            "either           frequency: 15362     POS: adverb\n",
            "wife             frequency: 15246     POS: noun\n",
            "victory          frequency: 15222     POS: noun\n",
            "robert           frequency: 15095     POS: noun\n",
            "mid              frequency: 14571     POS: adjective satellite\n",
            "successful       frequency: 14051     POS: adjective\n",
            "additional       frequency: 13194     POS: adjective satellite\n",
            "canada           frequency: 13078     POS: noun\n",
            "previously       frequency: 12958     POS: adverb\n",
            "california       frequency: 12757     POS: noun\n",
            "infantry         frequency: 12659     POS: noun\n",
            "germany          frequency: 12220     POS: noun\n",
            "india            frequency: 12190     POS: noun\n",
            "sometimes        frequency: 12171     POS: adverb\n",
            "already          frequency: 11853     POS: adverb\n",
            "usually          frequency: 11748     POS: adverb\n",
            "britain          frequency: 11362     POS: noun\n",
            "might            frequency: 10972     POS: noun\n",
            "percent          frequency: 10904     POS: noun\n",
            "approximately    frequency: 10872     POS: adverb\n",
            "naval            frequency: 10838     POS: adjective\n",
            "daughter         frequency: 10695     POS: noun\n",
            "subsequently     frequency: 10558     POS: adverb\n",
            "museum           frequency: 10312     POS: noun\n",
            "guitar           frequency: 10296     POS: noun\n",
            "billboard        frequency: 9983      POS: noun\n",
            "numerous         frequency: 9847      POS: adjective satellite\n",
            "florida          frequency: 9574      POS: noun\n",
            "texas            frequency: 9439      POS: noun\n",
            "movie            frequency: 9341      POS: noun\n",
            "mary             frequency: 9278      POS: noun\n",
            "valley           frequency: 9253      POS: noun\n",
            "entertainment    frequency: 9224      POS: noun\n",
            "africa           frequency: 9155      POS: noun\n",
            "artist           frequency: 9135      POS: noun\n",
            "respectively     frequency: 9006      POS: adverb\n",
            "prince           frequency: 8612      POS: noun\n",
            "stadium          frequency: 8271      POS: noun\n",
            "dvd              frequency: 8037      POS: noun\n",
            "ultimately       frequency: 7951      POS: adverb\n",
            "mexico           frequency: 7885      POS: noun\n",
            "financial        frequency: 7798      POS: adjective\n",
            "scotland         frequency: 7728      POS: noun\n",
            "airport          frequency: 7677      POS: noun\n",
            "zealand          frequency: 7581      POS: noun\n",
            "subsequent       frequency: 7457      POS: adjective\n",
            "relatively       frequency: 7203      POS: adverb\n",
            "concept          frequency: 7085      POS: noun\n",
            "boston           frequency: 7057      POS: noun\n",
            "alongside        frequency: 7052      POS: adverb\n",
            "historian        frequency: 6982      POS: noun\n",
            "soundtrack       frequency: 6904      POS: noun\n",
            "louis            frequency: 6848      POS: noun\n",
            "mainly           frequency: 6831      POS: adverb\n",
            "italy            frequency: 6724      POS: noun\n",
            "rainfall         frequency: 6490      POS: noun\n",
            "equipment        frequency: 6473      POS: noun\n",
            "hotel            frequency: 6449      POS: noun\n",
            "medal            frequency: 6343      POS: noun\n",
            "stephen          frequency: 6322      POS: noun\n",
            "typically        frequency: 6170      POS: adverb\n",
            "why              frequency: 6122      POS: noun\n",
            "carolina         frequency: 6044      POS: noun\n",
            "frequently       frequency: 5976      POS: adverb\n",
            "tech             frequency: 5960      POS: noun\n",
            "famous           frequency: 5843      POS: adjective satellite\n",
            "newly            frequency: 5769      POS: adverb\n",
            "website          frequency: 5764      POS: noun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding additional replacement words with more similar words"
      ],
      "metadata": {
        "id": "GkJQj4IvhYE4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3Q11jiyC5lR",
        "outputId": "47498ab4-ef68-484c-f375-57e7c1d92e58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 11338 valid BERT vocab words.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 998 top 10% frequency words.\n",
            "\n",
            "Top 10% frequency monosemous words with ≥10 similar words:\n",
            "\n",
            "Word: victory\n",
            "  Frequency: 15222\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 11\n",
            "  Similar words: ['ending', 'pin', 'sweep', 'independence', 'triumph', 'conclusion', 'finish', 'win', 'success', 'fall']\n",
            "\n",
            "Word: praised\n",
            "  Frequency: 13287\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 9\n",
            "  Similar words: ['laud', 'push', 'promote', 'proclaim', 'praise', 'value', 'measure', 'recommend', 'assess']\n",
            "\n",
            "Word: highway\n",
            "  Frequency: 22802\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 8\n",
            "  Similar words: ['motorway', 'pike', 'expressway', 'route', 'freeway', 'road', 'bypass', 'interstate']\n",
            "\n",
            "Word: almost\n",
            "  Frequency: 16835\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 5\n",
            "  Similar words: ['most', 'about', 'nearly', 'near', 'virtually']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from collections import Counter\n",
        "from datasets import load_dataset\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "vocab_file = \"vocab.txt\"\n",
        "bert_vocab = set()\n",
        "\n",
        "with open(vocab_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        token = line.strip()\n",
        "        if token.isalpha() and token.islower():\n",
        "            bert_vocab.add(token)\n",
        "\n",
        "print(f\"Loaded {len(bert_vocab)} valid BERT vocab words.\")\n",
        "\n",
        "dataset = load_dataset(\"wikitext\", \"wikitext-103-v1\")\n",
        "texts = dataset[\"train\"][\"text\"]\n",
        "\n",
        "freq_counter = Counter()\n",
        "for line in texts:\n",
        "    tokens = line.split()\n",
        "    for token in tokens:\n",
        "        token_lower = token.lower()\n",
        "        if token_lower.isalpha() and token_lower in bert_vocab:\n",
        "            freq_counter[token_lower] += 1\n",
        "\n",
        "def get_wordnet_similar_in_bert(word):\n",
        "    \"\"\"Return WordNet-based similar words that exist in BERT vocab.\"\"\"\n",
        "    related = set()\n",
        "    for syn in wn.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            related.add(lemma.name().lower())\n",
        "        for hyper in syn.hypernyms():\n",
        "            for lemma in hyper.lemmas():\n",
        "                related.add(lemma.name().lower())\n",
        "        for hypo in syn.hyponyms():\n",
        "            for lemma in hypo.lemmas():\n",
        "                related.add(lemma.name().lower())\n",
        "    related.discard(word)\n",
        "    return [w for w in related if w in bert_vocab]\n",
        "\n",
        "def get_num_synsets(word):\n",
        "    return len(wn.synsets(word))\n",
        "\n",
        "words_in_vocab = [w for w in bert_vocab if w in freq_counter]\n",
        "frequencies = sorted([freq_counter[w] for w in words_in_vocab])\n",
        "threshold = frequencies[int(0.9 * len(frequencies))]  # top 10%\n",
        "top_words = [w for w in words_in_vocab if freq_counter[w] >= threshold]\n",
        "\n",
        "print(f\"Found {len(top_words)} top 10% frequency words.\")\n",
        "\n",
        "monosemous_top_candidates = []\n",
        "for word in top_words:\n",
        "    num_syn = get_num_synsets(word)\n",
        "    if num_syn == 1:\n",
        "        similar = get_wordnet_similar_in_bert(word)\n",
        "        if len(similar) >= 5:\n",
        "            monosemous_top_candidates.append({\n",
        "                \"word\": word,\n",
        "                \"num_synsets\": num_syn,\n",
        "                \"frequency\": freq_counter[word],\n",
        "                \"num_similar\": len(similar),\n",
        "                \"similar_words\": similar[:10]\n",
        "            })\n",
        "\n",
        "monosemous_top_candidates_sorted = sorted(\n",
        "    monosemous_top_candidates,\n",
        "    key=lambda x: x[\"num_similar\"],\n",
        "    reverse=True\n",
        ")\n",
        "print(\"\\nTop 10% frequency monosemous words with ≥10 similar words:\\n\")\n",
        "for entry in monosemous_top_candidates_sorted[:20]:\n",
        "    print(f\"Word: {entry['word']}\")\n",
        "    print(f\"  Frequency: {entry['frequency']}\")\n",
        "    print(f\"  # Synsets: {entry['num_synsets']}\")\n",
        "    print(f\"  # Similar (in vocab): {entry['num_similar']}\")\n",
        "    print(f\"  Similar words: {entry['similar_words']}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now add victory, praised, highway, and almost into our list for frequent monosemous words."
      ],
      "metadata": {
        "id": "ux4KnoDvcLVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Frequent and Monosemous words list\n",
        "1. tennis\n",
        "2. guild\n",
        "3. grossing\n",
        "4. televised\n",
        "5. alleged\n",
        "6. victory\n",
        "7. praised\n",
        "8. highway\n",
        "9. almost\n",
        "10. mini\n"
      ],
      "metadata": {
        "id": "ojIuRwJYqe3W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confirm if in Bert Vocab"
      ],
      "metadata": {
        "id": "niW9qkWtq7M1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mono_freq = [\"tennis\", \"praised\", \"victory\", \"guild\", \"mini\", \"grossing\",\n",
        "             \"highway\", \"televised\", \"alleged\", \"almost\"]"
      ],
      "metadata": {
        "id": "FTvesaa6sPr8"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in mono_freq:\n",
        "  if word in bert_vocab:\n",
        "    print(f\"{word} is in the BERT vocab.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WrUEXe6rw84",
        "outputId": "dcf78d1a-bf46-4faa-e3c5-42b46f1ca485"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tennis is in the BERT vocab.\n",
            "praised is in the BERT vocab.\n",
            "victory is in the BERT vocab.\n",
            "guild is in the BERT vocab.\n",
            "mini is in the BERT vocab.\n",
            "grossing is in the BERT vocab.\n",
            "highway is in the BERT vocab.\n",
            "televised is in the BERT vocab.\n",
            "alleged is in the BERT vocab.\n",
            "almost is in the BERT vocab.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Infrequent Monosemous Words\n",
        "These words were randomly selected based on their POS to control for it. ** Edit to add: there is an error in this code, as the words are selected without considering if they are in our XT LTG Bert's vocab."
      ],
      "metadata": {
        "id": "aqmHaCPyD3Q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "bottom_10_percent_nouns_info = []\n",
        "\n",
        "for word in bottom_10_percent:\n",
        "    if not word.islower():\n",
        "        continue\n",
        "\n",
        "    synsets = wn.synsets(word)\n",
        "\n",
        "    noun_synsets = [syn for syn in synsets if syn.pos() == 'n' or syn.pos() == 'v']\n",
        "\n",
        "    if len(noun_synsets) > 0:\n",
        "        num_senses = len(noun_synsets)\n",
        "        pos_tags = [syn.pos() for syn in noun_synsets]\n",
        "\n",
        "        bottom_10_percent_nouns_info.append({\n",
        "            'word': word,\n",
        "            'num_synsets': num_senses,\n",
        "            'pos_tags': pos_tags\n",
        "        })\n",
        "\n",
        "for info in bottom_10_percent_nouns_info[:50]:\n",
        "    print(f\"Word: {info['word']}\")\n",
        "    print(f\"  Number of noun synsets: {info['num_synsets']}\")\n",
        "    print(f\"  POS tags: {info['pos_tags']}\")\n",
        "    print(\"-\" * 40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9IqINB9zz7Y",
        "outputId": "c932e5c8-0e5e-4dbb-fc0b-c0110cabb3ee"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: thalweg\n",
            "  Number of noun synsets: 2\n",
            "  POS tags: ['n', 'n']\n",
            "----------------------------------------\n",
            "Word: grovelling\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['v']\n",
            "----------------------------------------\n",
            "Word: louisianans\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: muckraker\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: duckboards\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: hangouts\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: caruncle\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: fivesome\n",
            "  Number of noun synsets: 2\n",
            "  POS tags: ['n', 'n']\n",
            "----------------------------------------\n",
            "Word: gyration\n",
            "  Number of noun synsets: 2\n",
            "  POS tags: ['n', 'n']\n",
            "----------------------------------------\n",
            "Word: serranus\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: stayers\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: makins\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: dairyman\n",
            "  Number of noun synsets: 2\n",
            "  POS tags: ['n', 'n']\n",
            "----------------------------------------\n",
            "Word: trundled\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['v']\n",
            "----------------------------------------\n",
            "Word: hypnotherapy\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: sponged\n",
            "  Number of noun synsets: 5\n",
            "  POS tags: ['v', 'v', 'v', 'v', 'v']\n",
            "----------------------------------------\n",
            "Word: ostracise\n",
            "  Number of noun synsets: 2\n",
            "  POS tags: ['v', 'v']\n",
            "----------------------------------------\n",
            "Word: spokeswomen\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: perplexities\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: groundskeepers\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: circumnavigations\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: transmutations\n",
            "  Number of noun synsets: 3\n",
            "  POS tags: ['n', 'n', 'n']\n",
            "----------------------------------------\n",
            "Word: overreact\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['v']\n",
            "----------------------------------------\n",
            "Word: shantytowns\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: librium\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: neuroleptics\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: oxazepam\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: potentiates\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['v']\n",
            "----------------------------------------\n",
            "Word: adjuncts\n",
            "  Number of noun synsets: 3\n",
            "  POS tags: ['n', 'n', 'n']\n",
            "----------------------------------------\n",
            "Word: pneumonectomy\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: palliation\n",
            "  Number of noun synsets: 2\n",
            "  POS tags: ['n', 'n']\n",
            "----------------------------------------\n",
            "Word: plugger\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: spanks\n",
            "  Number of noun synsets: 2\n",
            "  POS tags: ['n', 'v']\n",
            "----------------------------------------\n",
            "Word: circaetus\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: minters\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: kuwaitis\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: undervaluing\n",
            "  Number of noun synsets: 3\n",
            "  POS tags: ['v', 'v', 'v']\n",
            "----------------------------------------\n",
            "Word: toiletry\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: bronchiole\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: granuloma\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: tennesseans\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: hygrophoraceae\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: sabahan\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: daks\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: diabolism\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: divinations\n",
            "  Number of noun synsets: 3\n",
            "  POS tags: ['n', 'n', 'n']\n",
            "----------------------------------------\n",
            "Word: dainties\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: waked\n",
            "  Number of noun synsets: 5\n",
            "  POS tags: ['v', 'v', 'v', 'v', 'v']\n",
            "----------------------------------------\n",
            "Word: svr\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n",
            "Word: paramedical\n",
            "  Number of noun synsets: 1\n",
            "  POS tags: ['n']\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MKwZAMxT_kT",
        "outputId": "4617a915-7940-499f-cc94-cfca6f35fb76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Randomly selected infrequent monosemous nouns: ['masoud', 'pasto', 'sulfonate', 'calendula', 'prole']\n",
            "Randomly selected infrequent monosemous verbs: ['undersigned', 'idolise', 'gnashed', 'aestivating', 'construing']\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "eligible_monosem_nouns = []\n",
        "eligible_monosem_verbs = []\n",
        "\n",
        "for info in bottom_10_percent_nouns_info:\n",
        "    if info['num_synsets'] == 1:\n",
        "        synset_pos = info['pos_tags'][0]\n",
        "        if synset_pos == 'n':\n",
        "            eligible_monosem_nouns.append(info['word'])\n",
        "        elif synset_pos == 'v':\n",
        "            eligible_monosem_verbs.append(info['word'])\n",
        "\n",
        "infreq_monosem_nouns = random.sample(eligible_monosem_nouns, min(5, len(eligible_monosem_nouns)))\n",
        "infreq_monosem_verbs = random.sample(eligible_monosem_verbs, min(5, len(eligible_monosem_verbs)))\n",
        "\n",
        "print(\"Randomly selected infrequent monosemous nouns:\", infreq_monosem_nouns)\n",
        "print(\"Randomly selected infrequent monosemous verbs:\", infreq_monosem_verbs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some words did not have enough pre-existing similar words, so they were replaced by other ones that had more."
      ],
      "metadata": {
        "id": "1CqGOsJYTydk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCrlP-0UCDYS",
        "outputId": "36786cd3-42f7-4fa7-cddb-33633ac2c6f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11338 valid BERT vocab words.\n",
            "998 bottom 10% frequency words.\n",
            "\n",
            "Monosemous (1 synset) infrequent words with ≥10 similar words:\n",
            "\n",
            "Word: eff\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 11\n",
            "  Similar words: ['jazz', 'bed', 'have', 'love', 'take', 'couple', 'fuck', 'know', 'bang', 'pair']\n",
            "\n",
            "Word: bod\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 9\n",
            "  Similar words: ['anatomy', 'body', 'form', 'figure', 'flesh', 'shape', 'person', 'frame', 'build']\n",
            "\n",
            "Word: thous\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 6\n",
            "  Similar words: ['g', 'k', 'yard', 'grand', 'm', 'thousand']\n",
            "\n",
            "Word: diam\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 5\n",
            "  Similar words: ['bore', 'caliber', 'diameter', 'gauge', 'length']\n",
            "\n",
            "Word: deem\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 5\n",
            "  Similar words: ['regard', 'see', 'consider', 'view', 'hold']\n",
            "\n",
            "Word: annoy\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 5\n",
            "  Similar words: ['get', 'gravel', 'rag', 'devil', 'harry']\n",
            "\n",
            "Word: transact\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 5\n",
            "  Similar words: ['trade', 'bank', 'interact', 'sell', 'deal']\n",
            "\n",
            "Word: biz\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 5\n",
            "  Similar words: ['occupation', 'business', 'game', 'line', 'job']\n",
            "\n",
            "Word: lav\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 4\n",
            "  Similar words: ['can', 'head', 'john', 'room']\n",
            "\n",
            "Word: mete\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 4\n",
            "  Similar words: ['border', 'bound', 'circuit', 'boundary']\n",
            "\n",
            "Word: meth\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 4\n",
            "  Similar words: ['ice', 'glass', 'speed', 'upper']\n",
            "\n",
            "Word: rend\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 4\n",
            "  Similar words: ['pull', 'tear', 'rip', 'bust']\n",
            "\n",
            "Word: superintend\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 4\n",
            "  Similar words: ['manage', 'administer', 'oversee', 'build']\n",
            "\n",
            "Word: corp\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 4\n",
            "  Similar words: ['house', 'corporation', 'empire', 'firm']\n",
            "\n",
            "Word: comp\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 4\n",
            "  Similar words: ['test', 'examination', 'comprehensive', 'exam']\n",
            "\n",
            "Word: ell\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 3\n",
            "  Similar words: ['extension', 'wing', 'annex']\n",
            "\n",
            "Word: ess\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 3\n",
            "  Similar words: ['e', 'metal', 'es']\n",
            "\n",
            "Word: chore\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 3\n",
            "  Similar words: ['duty', 'job', 'task']\n",
            "\n",
            "Word: craw\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 3\n",
            "  Similar words: ['crop', 'stomach', 'tum']\n",
            "\n",
            "Word: ker\n",
            "  # Synsets: 1\n",
            "  # Similar (in vocab): 3\n",
            "  Similar words: ['k', 'm', 'thousand']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vocab_file = \"vocab.txt\"\n",
        "bert_vocab = set()\n",
        "\n",
        "with open(vocab_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        token = line.strip()\n",
        "        if token.isalpha() and token.islower():\n",
        "            bert_vocab.add(token)\n",
        "\n",
        "print(f\"{len(bert_vocab)} valid BERT vocab words.\")\n",
        "\n",
        "freq_counter = Counter()\n",
        "for line in texts:\n",
        "    tokens = line.split()\n",
        "    for token in tokens:\n",
        "        token_lower = token.lower()\n",
        "        if token_lower.isalpha() and token_lower in bert_vocab:\n",
        "            freq_counter[token_lower] += 1\n",
        "\n",
        "def get_wordnet_similar_in_bert(word):\n",
        "    \"\"\"Return WordNet-based similar words that exist in BERT vocab.\"\"\"\n",
        "    related = set()\n",
        "    for syn in wn.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            related.add(lemma.name().lower())\n",
        "        for hyper in syn.hypernyms():\n",
        "            for lemma in hyper.lemmas():\n",
        "                related.add(lemma.name().lower())\n",
        "        for hypo in syn.hyponyms():\n",
        "            for lemma in hypo.lemmas():\n",
        "                related.add(lemma.name().lower())\n",
        "    related.discard(word)\n",
        "    return [w for w in related if w in bert_vocab]\n",
        "\n",
        "def get_num_synsets(word):\n",
        "    return len(wn.synsets(word))\n",
        "\n",
        "words_in_vocab = [w for w in bert_vocab if w in freq_counter]\n",
        "frequencies = [freq_counter[w] for w in words_in_vocab]\n",
        "frequencies.sort()\n",
        "threshold = frequencies[int(0.1 * len(frequencies))]\n",
        "bottom_words = [w for w in words_in_vocab if freq_counter[w] <= threshold]\n",
        "\n",
        "print(f\"{len(bottom_words)} bottom 10% frequency words.\")\n",
        "\n",
        "monosemous_candidates = []\n",
        "for word in bottom_words:\n",
        "    num_syn = get_num_synsets(word)\n",
        "    if num_syn == 1:\n",
        "        similar = get_wordnet_similar_in_bert(word)\n",
        "        if len(similar) >= 3:\n",
        "            monosemous_candidates.append({\n",
        "                \"word\": word,\n",
        "                \"num_synsets\": num_syn,\n",
        "                \"num_similar\": len(similar),\n",
        "                \"similar_words\": similar[:10]\n",
        "            })\n",
        "\n",
        "monosemous_candidates_sorted = sorted(monosemous_candidates, key=lambda x: x[\"num_similar\"], reverse=True)\n",
        "print(\"\\nMonosemous (1 synset) infrequent words with ≥10 similar words:\\n\")\n",
        "for entry in monosemous_candidates_sorted[:20]:\n",
        "    print(f\"Word: {entry['word']}\")\n",
        "    print(f\"  # Synsets: {entry['num_synsets']}\")\n",
        "    print(f\"  # Similar (in vocab): {entry['num_similar']}\")\n",
        "    print(f\"  Similar words: {entry['similar_words']}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Infrequent Monosemous words list\n",
        "\n",
        "\n",
        "1.   denouncements\n",
        "2.   mortgagee\n",
        "3. pharmacologists\n",
        "4. legalises\n",
        "5. behoove\n",
        "6. demonise\n",
        "7. transact\n",
        "8. eff\n",
        "9. bod\n",
        "10. deem\n",
        "\n"
      ],
      "metadata": {
        "id": "04fkhDDzUUWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confirm if in Bert Vocab:\n"
      ],
      "metadata": {
        "id": "G4kANMktiSTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_im= [\"denouncements\", \"mortgagee\", \"eff\", \"pharmacologists\",\n",
        "               \"bod\", \"legalises\", \"behoove\", \"demonise\", \"transace\", \"deem\"]"
      ],
      "metadata": {
        "id": "B_G2yE0uiBdS"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in final_im:\n",
        "  if word in bert_vocab:\n",
        "    print(f\"{word} is in the BERT vocab.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Das1BlDUiXe0",
        "outputId": "237f4e70-ce5a-4eaf-d7f9-d8364afe1b1e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eff is in the BERT vocab.\n",
            "bod is in the BERT vocab.\n",
            "deem is in the BERT vocab.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Putting together a master dictionary in the end"
      ],
      "metadata": {
        "id": "rjhDkq3LVhG_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32b90c44-999d-4688-b2fc-7c8b540578bc",
        "id": "jCF5VeTPuJpW"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 11338 BERT vocab words.\n",
            "\n",
            "The word 'tennis' has only 2 similar words:\n",
            "['doubles', 'singles']\n",
            "Add an additional similar word for 'tennis': sport\n",
            "Added 'sport' to similar_words.\n",
            "\n",
            "The word 'tennis' has only 3 similar words:\n",
            "['doubles', 'singles', 'sport']\n",
            "Add an additional similar word for 'tennis': duo\n",
            "Added 'duo' to similar_words.\n",
            "\n",
            "The word 'tennis' has only 4 similar words:\n",
            "['doubles', 'singles', 'sport', 'duo']\n",
            "Add an additional similar word for 'tennis': ball\n",
            "Added 'ball' to similar_words.\n",
            "\n",
            "The word 'tennis' has only 5 similar words:\n",
            "['doubles', 'singles', 'sport', 'duo', 'ball']\n",
            "Add an additional similar word for 'tennis': net\n",
            "Added 'net' to similar_words.\n",
            "\n",
            "The word 'tennis' has only 6 similar words:\n",
            "['doubles', 'singles', 'sport', 'duo', 'ball', 'net']\n",
            "Add an additional similar word for 'tennis': court\n",
            "Added 'court' to similar_words.\n",
            "\n",
            "The word 'tennis' has only 7 similar words:\n",
            "['doubles', 'singles', 'sport', 'duo', 'ball', 'net', 'court']\n",
            "Add an additional similar word for 'tennis': serve\n",
            "Added 'serve' to similar_words.\n",
            "\n",
            "The word 'tennis' has only 8 similar words:\n",
            "['doubles', 'singles', 'sport', 'duo', 'ball', 'net', 'court', 'serve']\n",
            "Add an additional similar word for 'tennis': hit\n",
            "Added 'hit' to similar_words.\n",
            "\n",
            "The word 'tennis' has only 9 similar words:\n",
            "['doubles', 'singles', 'sport', 'duo', 'ball', 'net', 'court', 'serve', 'hit']\n",
            "Add an additional similar word for 'tennis': smash\n",
            "Added 'smash' to similar_words.\n",
            "\n",
            "The word 'praised' has only 9 similar words:\n",
            "['recommend', 'push', 'measure', 'proclaim', 'assess', 'value', 'laud', 'praise', 'promote']\n",
            "Add an additional similar word for 'praised': worship\n",
            "Added 'worship' to similar_words.\n",
            "\n",
            "The word 'guild' has only 7 similar words:\n",
            "['order', 'chapter', 'club', 'association', 'hunt', 'lodge', 'society']\n",
            "Add an additional similar word for 'guild': group\n",
            "Added 'group' to similar_words.\n",
            "\n",
            "The word 'guild' has only 8 similar words:\n",
            "['order', 'chapter', 'club', 'association', 'hunt', 'lodge', 'society', 'group']\n",
            "Add an additional similar word for 'guild': members\n",
            "Added 'members' to similar_words.\n",
            "\n",
            "The word 'guild' has only 9 similar words:\n",
            "['order', 'chapter', 'club', 'association', 'hunt', 'lodge', 'society', 'group', 'members']\n",
            "Add an additional similar word for 'guild': union\n",
            "Added 'union' to similar_words.\n",
            "\n",
            "The word 'mini' has only 0 similar words:\n",
            "[]\n",
            "Add an additional similar word for 'mini': component\n",
            "Added 'component' to similar_words.\n",
            "\n",
            "The word 'mini' has only 1 similar words:\n",
            "['component']\n",
            "Add an additional similar word for 'mini': feature\n",
            "Added 'feature' to similar_words.\n",
            "\n",
            "The word 'mini' has only 2 similar words:\n",
            "['component', 'feature']\n",
            "Add an additional similar word for 'mini': part\n",
            "Added 'part' to similar_words.\n",
            "\n",
            "The word 'mini' has only 3 similar words:\n",
            "['component', 'feature', 'part']\n",
            "Add an additional similar word for 'mini': micro\n",
            "Added 'micro' to similar_words.\n",
            "\n",
            "The word 'mini' has only 4 similar words:\n",
            "['component', 'feature', 'part', 'micro']\n",
            "Add an additional similar word for 'mini': compact\n",
            "Added 'compact' to similar_words.\n",
            "\n",
            "The word 'mini' has only 5 similar words:\n",
            "['component', 'feature', 'part', 'micro', 'compact']\n",
            "Add an additional similar word for 'mini': magnitude\n",
            "Added 'magnitude' to similar_words.\n",
            "\n",
            "The word 'mini' has only 6 similar words:\n",
            "['component', 'feature', 'part', 'micro', 'compact', 'magnitude']\n",
            "Add an additional similar word for 'mini': scale\n",
            "Added 'scale' to similar_words.\n",
            "\n",
            "The word 'mini' has only 7 similar words:\n",
            "['component', 'feature', 'part', 'micro', 'compact', 'magnitude', 'scale']\n",
            "Add an additional similar word for 'mini': size\n",
            "Added 'size' to similar_words.\n",
            "\n",
            "The word 'mini' has only 8 similar words:\n",
            "['component', 'feature', 'part', 'micro', 'compact', 'magnitude', 'scale', 'size']\n",
            "Add an additional similar word for 'mini': tiny\n",
            "Added 'tiny' to similar_words.\n",
            "\n",
            "The word 'mini' has only 9 similar words:\n",
            "['component', 'feature', 'part', 'micro', 'compact', 'magnitude', 'scale', 'size', 'tiny']\n",
            "Add an additional similar word for 'mini': small\n",
            "Added 'small' to similar_words.\n",
            "\n",
            "The word 'grossing' has only 6 similar words:\n",
            "['realize', 'earn', 'clear', 'make', 'gross', 'gain']\n",
            "Add an additional similar word for 'grossing': income\n",
            "Added 'income' to similar_words.\n",
            "\n",
            "The word 'grossing' has only 7 similar words:\n",
            "['realize', 'earn', 'clear', 'make', 'gross', 'gain', 'income']\n",
            "Add an additional similar word for 'grossing': sales\n",
            "Added 'sales' to similar_words.\n",
            "\n",
            "The word 'grossing' has only 8 similar words:\n",
            "['realize', 'earn', 'clear', 'make', 'gross', 'gain', 'income', 'sales']\n",
            "Add an additional similar word for 'grossing': revenue\n",
            "Added 'revenue' to similar_words.\n",
            "\n",
            "The word 'grossing' has only 9 similar words:\n",
            "['realize', 'earn', 'clear', 'make', 'gross', 'gain', 'income', 'sales', 'revenue']\n",
            "Add an additional similar word for 'grossing': profit\n",
            "Added 'profit' to similar_words.\n",
            "\n",
            "The word 'highway' has only 8 similar words:\n",
            "['freeway', 'interstate', 'motorway', 'bypass', 'pike', 'road', 'expressway', 'route']\n",
            "Add an additional similar word for 'highway': realize\n",
            "Added 'realize' to similar_words.\n",
            "\n",
            "The word 'highway' has only 9 similar words:\n",
            "['freeway', 'interstate', 'motorway', 'bypass', 'pike', 'road', 'expressway', 'route', 'realize']\n",
            "Add an additional similar word for 'highway': car\n",
            "Added 'car' to similar_words.\n",
            "\n",
            "The word 'televised' has only 4 similar words:\n",
            "['broadcast', 'send', 'air', 'beam']\n",
            "Add an additional similar word for 'televised': news\n",
            "Added 'news' to similar_words.\n",
            "\n",
            "The word 'televised' has only 5 similar words:\n",
            "['broadcast', 'send', 'air', 'beam', 'news']\n",
            "Add an additional similar word for 'televised': anchor\n",
            "Added 'anchor' to similar_words.\n",
            "\n",
            "The word 'televised' has only 6 similar words:\n",
            "['broadcast', 'send', 'air', 'beam', 'news', 'anchor']\n",
            "Add an additional similar word for 'televised': screen\n",
            "Added 'screen' to similar_words.\n",
            "\n",
            "The word 'televised' has only 7 similar words:\n",
            "['broadcast', 'send', 'air', 'beam', 'news', 'anchor', 'screen']\n",
            "Add an additional similar word for 'televised': media\n",
            "Added 'media' to similar_words.\n",
            "\n",
            "The word 'televised' has only 8 similar words:\n",
            "['broadcast', 'send', 'air', 'beam', 'news', 'anchor', 'screen', 'media']\n",
            "Add an additional similar word for 'televised': live\n",
            "Added 'live' to similar_words.\n",
            "\n",
            "The word 'televised' has only 9 similar words:\n",
            "['broadcast', 'send', 'air', 'beam', 'news', 'anchor', 'screen', 'media', 'live']\n",
            "Add an additional similar word for 'televised': communication\n",
            "Added 'communication' to similar_words.\n",
            "\n",
            "The word 'alleged' has only 5 similar words:\n",
            "['supposed', 'assert', 'say', 'aver', 'maintain']\n",
            "Add an additional similar word for 'alleged': victim\n",
            "Added 'victim' to similar_words.\n",
            "\n",
            "The word 'alleged' has only 6 similar words:\n",
            "['supposed', 'assert', 'say', 'aver', 'maintain', 'victim']\n",
            "Add an additional similar word for 'alleged': report\n",
            "Added 'report' to similar_words.\n",
            "\n",
            "The word 'alleged' has only 7 similar words:\n",
            "['supposed', 'assert', 'say', 'aver', 'maintain', 'victim', 'report']\n",
            "Add an additional similar word for 'alleged': crime\n",
            "Added 'crime' to similar_words.\n",
            "\n",
            "The word 'alleged' has only 8 similar words:\n",
            "['supposed', 'assert', 'say', 'aver', 'maintain', 'victim', 'report', 'crime']\n",
            "Add an additional similar word for 'alleged': statement\n",
            "Added 'statement' to similar_words.\n",
            "\n",
            "The word 'alleged' has only 9 similar words:\n",
            "['supposed', 'assert', 'say', 'aver', 'maintain', 'victim', 'report', 'crime', 'statement']\n",
            "Add an additional similar word for 'alleged': claim\n",
            "Added 'claim' to similar_words.\n",
            "\n",
            "The word 'almost' has only 5 similar words:\n",
            "['virtually', 'about', 'most', 'nearly', 'near']\n",
            "Add an additional similar word for 'almost': closely\n",
            "Added 'closely' to similar_words.\n",
            "\n",
            "The word 'almost' has only 6 similar words:\n",
            "['virtually', 'about', 'most', 'nearly', 'near', 'closely']\n",
            "Add an additional similar word for 'almost': around\n",
            "Added 'around' to similar_words.\n",
            "\n",
            "The word 'almost' has only 7 similar words:\n",
            "['virtually', 'about', 'most', 'nearly', 'near', 'closely', 'around']\n",
            "Add an additional similar word for 'almost': degree\n",
            "Added 'degree' to similar_words.\n",
            "\n",
            "The word 'almost' has only 8 similar words:\n",
            "['virtually', 'about', 'most', 'nearly', 'near', 'closely', 'around', 'degree']\n",
            "Add an additional similar word for 'almost': approximately\n",
            "Added 'approximately' to similar_words.\n",
            "\n",
            "The word 'almost' has only 9 similar words:\n",
            "['virtually', 'about', 'most', 'nearly', 'near', 'closely', 'around', 'degree', 'approximately']\n",
            "Add an additional similar word for 'almost': roughly\n",
            "Added 'roughly' to similar_words.\n",
            "\n",
            "The word 'denouncements' has only 1 similar words:\n",
            "['curse']\n",
            "Add an additional similar word for 'denouncements': official\n",
            "Added 'official' to similar_words.\n",
            "\n",
            "The word 'denouncements' has only 2 similar words:\n",
            "['curse', 'official']\n",
            "Add an additional similar word for 'denouncements': criticism\n",
            "Added 'criticism' to similar_words.\n",
            "\n",
            "The word 'denouncements' has only 3 similar words:\n",
            "['curse', 'official', 'criticism']\n",
            "Add an additional similar word for 'denouncements': opinion\n",
            "Added 'opinion' to similar_words.\n",
            "\n",
            "The word 'denouncements' has only 4 similar words:\n",
            "['curse', 'official', 'criticism', 'opinion']\n",
            "Add an additional similar word for 'denouncements': charges\n",
            "Added 'charges' to similar_words.\n",
            "\n",
            "The word 'denouncements' has only 5 similar words:\n",
            "['curse', 'official', 'criticism', 'opinion', 'charges']\n",
            "Add an additional similar word for 'denouncements': report\n",
            "Added 'report' to similar_words.\n",
            "\n",
            "The word 'denouncements' has only 6 similar words:\n",
            "['curse', 'official', 'criticism', 'opinion', 'charges', 'report']\n",
            "Add an additional similar word for 'denouncements': reject\n",
            "Added 'reject' to similar_words.\n",
            "\n",
            "The word 'denouncements' has only 7 similar words:\n",
            "['curse', 'official', 'criticism', 'opinion', 'charges', 'report', 'reject']\n",
            "Add an additional similar word for 'denouncements': declaration\n",
            "Added 'declaration' to similar_words.\n",
            "\n",
            "The word 'denouncements' has only 8 similar words:\n",
            "['curse', 'official', 'criticism', 'opinion', 'charges', 'report', 'reject', 'declaration']\n",
            "Add an additional similar word for 'denouncements': public\n",
            "Added 'public' to similar_words.\n",
            "\n",
            "The word 'denouncements' has only 9 similar words:\n",
            "['curse', 'official', 'criticism', 'opinion', 'charges', 'report', 'reject', 'declaration', 'public']\n",
            "Add an additional similar word for 'denouncements': statement\n",
            "Added 'statement' to similar_words.\n",
            "\n",
            "The word 'mortgagee' has only 0 similar words:\n",
            "[]\n",
            "Add an additional similar word for 'mortgagee': money\n",
            "Added 'money' to similar_words.\n",
            "\n",
            "The word 'mortgagee' has only 1 similar words:\n",
            "['money']\n",
            "Add an additional similar word for 'mortgagee': debt\n",
            "Added 'debt' to similar_words.\n",
            "\n",
            "The word 'mortgagee' has only 2 similar words:\n",
            "['money', 'debt']\n",
            "Add an additional similar word for 'mortgagee': credit\n",
            "Added 'credit' to similar_words.\n",
            "\n",
            "The word 'mortgagee' has only 3 similar words:\n",
            "['money', 'debt', 'credit']\n",
            "Add an additional similar word for 'mortgagee': bank\n",
            "Added 'bank' to similar_words.\n",
            "\n",
            "The word 'mortgagee' has only 4 similar words:\n",
            "['money', 'debt', 'credit', 'bank']\n",
            "Add an additional similar word for 'mortgagee': contract\n",
            "Added 'contract' to similar_words.\n",
            "\n",
            "The word 'mortgagee' has only 5 similar words:\n",
            "['money', 'debt', 'credit', 'bank', 'contract']\n",
            "Add an additional similar word for 'mortgagee': invest\n",
            "Added 'invest' to similar_words.\n",
            "\n",
            "The word 'mortgagee' has only 6 similar words:\n",
            "['money', 'debt', 'credit', 'bank', 'contract', 'invest']\n",
            "Add an additional similar word for 'mortgagee': property\n",
            "Added 'property' to similar_words.\n",
            "\n",
            "The word 'mortgagee' has only 7 similar words:\n",
            "['money', 'debt', 'credit', 'bank', 'contract', 'invest', 'property']\n",
            "Add an additional similar word for 'mortgagee': loan\n",
            "Added 'loan' to similar_words.\n",
            "\n",
            "The word 'mortgagee' has only 8 similar words:\n",
            "['money', 'debt', 'credit', 'bank', 'contract', 'invest', 'property', 'loan']\n",
            "Add an additional similar word for 'mortgagee': interest\n",
            "Added 'interest' to similar_words.\n",
            "\n",
            "The word 'mortgagee' has only 9 similar words:\n",
            "['money', 'debt', 'credit', 'bank', 'contract', 'invest', 'property', 'loan', 'interest']\n",
            "Add an additional similar word for 'mortgagee': lend\n",
            "Added 'lend' to similar_words.\n",
            "\n",
            "The word 'pharmacologists' has only 0 similar words:\n",
            "[]\n",
            "Add an additional similar word for 'pharmacologists': drugs\n",
            "Added 'drugs' to similar_words.\n",
            "\n",
            "The word 'pharmacologists' has only 1 similar words:\n",
            "['drugs']\n",
            "Add an additional similar word for 'pharmacologists': chemical\n",
            "Added 'chemical' to similar_words.\n",
            "\n",
            "The word 'pharmacologists' has only 2 similar words:\n",
            "['drugs', 'chemical']\n",
            "Add an additional similar word for 'pharmacologists': experiment\n",
            "Added 'experiment' to similar_words.\n",
            "\n",
            "The word 'pharmacologists' has only 3 similar words:\n",
            "['drugs', 'chemical', 'experiment']\n",
            "Add an additional similar word for 'pharmacologists': doctor\n",
            "Added 'doctor' to similar_words.\n",
            "\n",
            "The word 'pharmacologists' has only 4 similar words:\n",
            "['drugs', 'chemical', 'experiment', 'doctor']\n",
            "Add an additional similar word for 'pharmacologists': medicine\n",
            "Added 'medicine' to similar_words.\n",
            "\n",
            "The word 'pharmacologists' has only 5 similar words:\n",
            "['drugs', 'chemical', 'experiment', 'doctor', 'medicine']\n",
            "Add an additional similar word for 'pharmacologists': company\n",
            "Added 'company' to similar_words.\n",
            "\n",
            "The word 'pharmacologists' has only 6 similar words:\n",
            "['drugs', 'chemical', 'experiment', 'doctor', 'medicine', 'company']\n",
            "Add an additional similar word for 'pharmacologists': industry\n",
            "Added 'industry' to similar_words.\n",
            "\n",
            "The word 'pharmacologists' has only 7 similar words:\n",
            "['drugs', 'chemical', 'experiment', 'doctor', 'medicine', 'company', 'industry']\n",
            "Add an additional similar word for 'pharmacologists': health\n",
            "Added 'health' to similar_words.\n",
            "\n",
            "The word 'pharmacologists' has only 8 similar words:\n",
            "['drugs', 'chemical', 'experiment', 'doctor', 'medicine', 'company', 'industry', 'health']\n",
            "Add an additional similar word for 'pharmacologists': laboratory\n",
            "Added 'laboratory' to similar_words.\n",
            "\n",
            "The word 'pharmacologists' has only 9 similar words:\n",
            "['drugs', 'chemical', 'experiment', 'doctor', 'medicine', 'company', 'industry', 'health', 'laboratory']\n",
            "Add an additional similar word for 'pharmacologists': trials\n",
            "Added 'trials' to similar_words.\n",
            "\n",
            "The word 'bod' has only 9 similar words:\n",
            "['anatomy', 'figure', 'shape', 'form', 'person', 'flesh', 'frame', 'body', 'build']\n",
            "Add an additional similar word for 'bod': physical\n",
            "Added 'physical' to similar_words.\n",
            "\n",
            "The word 'legalises' has only 4 similar words:\n",
            "['let', 'allow', 'permit', 'legitimate']\n",
            "Add an additional similar word for 'legalises': enact\n",
            "Added 'enact' to similar_words.\n",
            "\n",
            "The word 'legalises' has only 5 similar words:\n",
            "['let', 'allow', 'permit', 'legitimate', 'enact']\n",
            "Add an additional similar word for 'legalises': license\n",
            "Added 'license' to similar_words.\n",
            "\n",
            "The word 'legalises' has only 6 similar words:\n",
            "['let', 'allow', 'permit', 'legitimate', 'enact', 'license']\n",
            "Add an additional similar word for 'legalises': statute\n",
            "Added 'statute' to similar_words.\n",
            "\n",
            "The word 'legalises' has only 7 similar words:\n",
            "['let', 'allow', 'permit', 'legitimate', 'enact', 'license', 'statute']\n",
            "Add an additional similar word for 'legalises': act\n",
            "Added 'act' to similar_words.\n",
            "\n",
            "The word 'legalises' has only 8 similar words:\n",
            "['let', 'allow', 'permit', 'legitimate', 'enact', 'license', 'statute', 'act']\n",
            "Add an additional similar word for 'legalises': law\n",
            "Added 'law' to similar_words.\n",
            "\n",
            "The word 'legalises' has only 9 similar words:\n",
            "['let', 'allow', 'permit', 'legitimate', 'enact', 'license', 'statute', 'act', 'law']\n",
            "Add an additional similar word for 'legalises': authority\n",
            "Added 'authority' to similar_words.\n",
            "\n",
            "The word 'behoove' has only 2 similar words:\n",
            "['meet', 'fit']\n",
            "Add an additional similar word for 'behoove': merit\n",
            "Added 'merit' to similar_words.\n",
            "\n",
            "The word 'behoove' has only 3 similar words:\n",
            "['meet', 'fit', 'merit']\n",
            "Add an additional similar word for 'behoove': advantage\n",
            "Added 'advantage' to similar_words.\n",
            "\n",
            "The word 'behoove' has only 4 similar words:\n",
            "['meet', 'fit', 'merit', 'advantage']\n",
            "Add an additional similar word for 'behoove': require\n",
            "Added 'require' to similar_words.\n",
            "\n",
            "The word 'behoove' has only 5 similar words:\n",
            "['meet', 'fit', 'merit', 'advantage', 'require']\n",
            "Add an additional similar word for 'behoove': responsibility\n",
            "Added 'responsibility' to similar_words.\n",
            "\n",
            "The word 'behoove' has only 6 similar words:\n",
            "['meet', 'fit', 'merit', 'advantage', 'require', 'responsibility']\n",
            "Add an additional similar word for 'behoove': duty\n",
            "Added 'duty' to similar_words.\n",
            "\n",
            "The word 'behoove' has only 7 similar words:\n",
            "['meet', 'fit', 'merit', 'advantage', 'require', 'responsibility', 'duty']\n",
            "Add an additional similar word for 'behoove': servve\n",
            "'servve' is not in BERT vocab or already in the list. Try again.\n",
            "\n",
            "The word 'behoove' has only 7 similar words:\n",
            "['meet', 'fit', 'merit', 'advantage', 'require', 'responsibility', 'duty']\n",
            "Add an additional similar word for 'behoove': suit\n",
            "Added 'suit' to similar_words.\n",
            "\n",
            "The word 'behoove' has only 8 similar words:\n",
            "['meet', 'fit', 'merit', 'advantage', 'require', 'responsibility', 'duty', 'suit']\n",
            "Add an additional similar word for 'behoove': benefit\n",
            "Added 'benefit' to similar_words.\n",
            "\n",
            "The word 'behoove' has only 9 similar words:\n",
            "['meet', 'fit', 'merit', 'advantage', 'require', 'responsibility', 'duty', 'suit', 'benefit']\n",
            "Add an additional similar word for 'behoove': serve\n",
            "Added 'serve' to similar_words.\n",
            "\n",
            "The word 'demonise' has only 2 similar words:\n",
            "['alter', 'change']\n",
            "Add an additional similar word for 'demonise': villain\n",
            "Added 'villain' to similar_words.\n",
            "\n",
            "The word 'demonise' has only 3 similar words:\n",
            "['alter', 'change', 'villain']\n",
            "Add an additional similar word for 'demonise': attack\n",
            "Added 'attack' to similar_words.\n",
            "\n",
            "The word 'demonise' has only 4 similar words:\n",
            "['alter', 'change', 'villain', 'attack']\n",
            "Add an additional similar word for 'demonise': criticism\n",
            "Added 'criticism' to similar_words.\n",
            "\n",
            "The word 'demonise' has only 5 similar words:\n",
            "['alter', 'change', 'villain', 'attack', 'criticism']\n",
            "Add an additional similar word for 'demonise': abuse\n",
            "Added 'abuse' to similar_words.\n",
            "\n",
            "The word 'demonise' has only 6 similar words:\n",
            "['alter', 'change', 'villain', 'attack', 'criticism', 'abuse']\n",
            "Add an additional similar word for 'demonise': reputation\n",
            "Added 'reputation' to similar_words.\n",
            "\n",
            "The word 'demonise' has only 7 similar words:\n",
            "['alter', 'change', 'villain', 'attack', 'criticism', 'abuse', 'reputation']\n",
            "Add an additional similar word for 'demonise': character\n",
            "Added 'character' to similar_words.\n",
            "\n",
            "The word 'demonise' has only 8 similar words:\n",
            "['alter', 'change', 'villain', 'attack', 'criticism', 'abuse', 'reputation', 'character']\n",
            "Add an additional similar word for 'demonise': image\n",
            "Added 'image' to similar_words.\n",
            "\n",
            "The word 'demonise' has only 9 similar words:\n",
            "['alter', 'change', 'villain', 'attack', 'criticism', 'abuse', 'reputation', 'character', 'image']\n",
            "Add an additional similar word for 'demonise': opinion\n",
            "Added 'opinion' to similar_words.\n",
            "\n",
            "The word 'transact' has only 5 similar words:\n",
            "['trade', 'interact', 'bank', 'sell', 'deal']\n",
            "Add an additional similar word for 'transact': goods\n",
            "Added 'goods' to similar_words.\n",
            "\n",
            "The word 'transact' has only 6 similar words:\n",
            "['trade', 'interact', 'bank', 'sell', 'deal', 'goods']\n",
            "Add an additional similar word for 'transact': buy\n",
            "Added 'buy' to similar_words.\n",
            "\n",
            "The word 'transact' has only 7 similar words:\n",
            "['trade', 'interact', 'bank', 'sell', 'deal', 'goods', 'buy']\n",
            "Add an additional similar word for 'transact': machine\n",
            "Added 'machine' to similar_words.\n",
            "\n",
            "The word 'transact' has only 8 similar words:\n",
            "['trade', 'interact', 'bank', 'sell', 'deal', 'goods', 'buy', 'machine']\n",
            "Add an additional similar word for 'transact': partner\n",
            "Added 'partner' to similar_words.\n",
            "\n",
            "The word 'transact' has only 9 similar words:\n",
            "['trade', 'interact', 'bank', 'sell', 'deal', 'goods', 'buy', 'machine', 'partner']\n",
            "Add an additional similar word for 'transact': money\n",
            "Added 'money' to similar_words.\n",
            "\n",
            "The word 'deem' has only 5 similar words:\n",
            "['regard', 'view', 'consider', 'hold', 'see']\n",
            "Add an additional similar word for 'deem': rate\n",
            "Added 'rate' to similar_words.\n",
            "\n",
            "The word 'deem' has only 6 similar words:\n",
            "['regard', 'view', 'consider', 'hold', 'see', 'rate']\n",
            "Add an additional similar word for 'deem': thought\n",
            "Added 'thought' to similar_words.\n",
            "\n",
            "The word 'deem' has only 7 similar words:\n",
            "['regard', 'view', 'consider', 'hold', 'see', 'rate', 'thought']\n",
            "Add an additional similar word for 'deem': mind\n",
            "Added 'mind' to similar_words.\n",
            "\n",
            "The word 'deem' has only 8 similar words:\n",
            "['regard', 'view', 'consider', 'hold', 'see', 'rate', 'thought', 'mind']\n",
            "Add an additional similar word for 'deem': believe\n",
            "Added 'believe' to similar_words.\n",
            "\n",
            "The word 'deem' has only 9 similar words:\n",
            "['regard', 'view', 'consider', 'hold', 'see', 'rate', 'thought', 'mind', 'believe']\n",
            "Add an additional similar word for 'deem': judge\n",
            "Added 'judge' to similar_words.\n",
            "{ 'target_words': [ { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 75,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'younger',\n",
            "                                        'scenario',\n",
            "                                        'supplies',\n",
            "                                        'delays',\n",
            "                                        'clut',\n",
            "                                        'themes',\n",
            "                                        'corn',\n",
            "                                        'genuine',\n",
            "                                        'effect',\n",
            "                                        'rome'],\n",
            "                      'similar_words': [ 'hurt',\n",
            "                                         'divide',\n",
            "                                         'dance',\n",
            "                                         'work',\n",
            "                                         'exchange',\n",
            "                                         'blow',\n",
            "                                         'damage',\n",
            "                                         'harm',\n",
            "                                         'talk',\n",
            "                                         'better'],\n",
            "                      'word': 'break'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 70,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'agents',\n",
            "                                        'preliminary',\n",
            "                                        'dedication',\n",
            "                                        'ket',\n",
            "                                        'environment',\n",
            "                                        'ignored',\n",
            "                                        'gren',\n",
            "                                        'arb',\n",
            "                                        'yugoslav',\n",
            "                                        'vict'],\n",
            "                      'similar_words': [ 'rib',\n",
            "                                         'tap',\n",
            "                                         'transit',\n",
            "                                         'shot',\n",
            "                                         'crop',\n",
            "                                         'hob',\n",
            "                                         'create',\n",
            "                                         'opening',\n",
            "                                         'resolve',\n",
            "                                         'chase'],\n",
            "                      'word': 'cut'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 52,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'langu',\n",
            "                                        'some',\n",
            "                                        'locations',\n",
            "                                        'billion',\n",
            "                                        'wider',\n",
            "                                        'station',\n",
            "                                        'ash',\n",
            "                                        'vincent',\n",
            "                                        'ɟ',\n",
            "                                        'eaten'],\n",
            "                      'similar_words': [ 'speed',\n",
            "                                         'flow',\n",
            "                                         'rushing',\n",
            "                                         'release',\n",
            "                                         'campaign',\n",
            "                                         'carry',\n",
            "                                         'succeed',\n",
            "                                         'trade',\n",
            "                                         'lean',\n",
            "                                         'rub'],\n",
            "                      'word': 'running'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 52,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'justin',\n",
            "                                        'aids',\n",
            "                                        'gunn',\n",
            "                                        'themed',\n",
            "                                        'elsewhere',\n",
            "                                        'g',\n",
            "                                        'troub',\n",
            "                                        'definition',\n",
            "                                        'bom',\n",
            "                                        'discl'],\n",
            "                      'similar_words': [ 'parody',\n",
            "                                         'beat',\n",
            "                                         'ham',\n",
            "                                         'perform',\n",
            "                                         'walk',\n",
            "                                         'exercise',\n",
            "                                         'die',\n",
            "                                         'retire',\n",
            "                                         'shot',\n",
            "                                         'doctor'],\n",
            "                      'word': 'play'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 51,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'rarely',\n",
            "                                        'data',\n",
            "                                        'marriage',\n",
            "                                        'crown',\n",
            "                                        'cere',\n",
            "                                        'vietnamese',\n",
            "                                        'parliam',\n",
            "                                        'anthem',\n",
            "                                        'mail',\n",
            "                                        'hann'],\n",
            "                      'similar_words': [ 'render',\n",
            "                                         'elaborate',\n",
            "                                         'cut',\n",
            "                                         'pull',\n",
            "                                         'gross',\n",
            "                                         'number',\n",
            "                                         'incorporate',\n",
            "                                         'take',\n",
            "                                         'leave',\n",
            "                                         'be'],\n",
            "                      'word': 'make'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 50,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'napoleon',\n",
            "                                        'jos',\n",
            "                                        'download',\n",
            "                                        'associ',\n",
            "                                        'day',\n",
            "                                        'disorder',\n",
            "                                        'inhabited',\n",
            "                                        'aus',\n",
            "                                        'voted',\n",
            "                                        'ke'],\n",
            "                      'similar_words': [ 'break',\n",
            "                                         'substantially',\n",
            "                                         'well',\n",
            "                                         'surge',\n",
            "                                         'raise',\n",
            "                                         'down',\n",
            "                                         'surpass',\n",
            "                                         'near',\n",
            "                                         'recover',\n",
            "                                         'upgrade'],\n",
            "                      'word': 'better'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 47,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'blamed',\n",
            "                                        'storms',\n",
            "                                        'resolution',\n",
            "                                        'creat',\n",
            "                                        'mainstream',\n",
            "                                        'declining',\n",
            "                                        'defender',\n",
            "                                        'indians',\n",
            "                                        'weeks',\n",
            "                                        'inf'],\n",
            "                      'similar_words': [ 'meteor',\n",
            "                                         'status',\n",
            "                                         'expression',\n",
            "                                         'flood',\n",
            "                                         'glory',\n",
            "                                         'weak',\n",
            "                                         'condition',\n",
            "                                         'perspective',\n",
            "                                         'clear',\n",
            "                                         'lighter'],\n",
            "                      'word': 'light'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 46,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'food',\n",
            "                                        'nearly',\n",
            "                                        'ceiling',\n",
            "                                        'shifted',\n",
            "                                        'combining',\n",
            "                                        'inch',\n",
            "                                        'nobody',\n",
            "                                        'dominated',\n",
            "                                        'deeply',\n",
            "                                        'sail'],\n",
            "                      'similar_words': [ 'begin',\n",
            "                                         'descend',\n",
            "                                         'precipitation',\n",
            "                                         'hail',\n",
            "                                         'slow',\n",
            "                                         'twilight',\n",
            "                                         'pin',\n",
            "                                         'pass',\n",
            "                                         'travel',\n",
            "                                         'weakening'],\n",
            "                      'word': 'falls'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 45,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'exc',\n",
            "                                        'those',\n",
            "                                        'toys',\n",
            "                                        'geography',\n",
            "                                        'fortress',\n",
            "                                        'taken',\n",
            "                                        'rust',\n",
            "                                        'hour',\n",
            "                                        'dylan',\n",
            "                                        'school'],\n",
            "                      'similar_words': [ 'permit',\n",
            "                                         'label',\n",
            "                                         'alter',\n",
            "                                         'remove',\n",
            "                                         'free',\n",
            "                                         'create',\n",
            "                                         'take',\n",
            "                                         'acquire',\n",
            "                                         'top',\n",
            "                                         'clean'],\n",
            "                      'word': 'clear'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 36,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'presumed',\n",
            "                                        'hardly',\n",
            "                                        'olympic',\n",
            "                                        'croat',\n",
            "                                        'invas',\n",
            "                                        'submarines',\n",
            "                                        'sector',\n",
            "                                        'broad',\n",
            "                                        'rene',\n",
            "                                        'rav'],\n",
            "                      'similar_words': [ 'butterfly',\n",
            "                                         'exhibit',\n",
            "                                         'grass',\n",
            "                                         'clear',\n",
            "                                         'display',\n",
            "                                         'turn',\n",
            "                                         'spread',\n",
            "                                         'candid',\n",
            "                                         'start',\n",
            "                                         'country'],\n",
            "                      'word': 'open'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 8,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'ɛ',\n",
            "                                        'towards',\n",
            "                                        'contributions',\n",
            "                                        'alongside',\n",
            "                                        'uk',\n",
            "                                        'jab',\n",
            "                                        'hail',\n",
            "                                        'protecting',\n",
            "                                        'partis',\n",
            "                                        'patent'],\n",
            "                      'similar_words': [ 'apply',\n",
            "                                         'cater',\n",
            "                                         'help',\n",
            "                                         'manage',\n",
            "                                         'run',\n",
            "                                         'employ',\n",
            "                                         'give',\n",
            "                                         'bed',\n",
            "                                         'travel',\n",
            "                                         'meet'],\n",
            "                      'word': 'ply'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 7,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'watt',\n",
            "                                        'norfolk',\n",
            "                                        'prosper',\n",
            "                                        'barb',\n",
            "                                        'laur',\n",
            "                                        'brid',\n",
            "                                        'lenn',\n",
            "                                        'canal',\n",
            "                                        'distract',\n",
            "                                        'fu'],\n",
            "                      'similar_words': [ 'mend',\n",
            "                                         'doctor',\n",
            "                                         'restore',\n",
            "                                         'manufacture',\n",
            "                                         'butterfly',\n",
            "                                         'support',\n",
            "                                         'patch',\n",
            "                                         'fix',\n",
            "                                         'backup',\n",
            "                                         'woman'],\n",
            "                      'word': 'vamp'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 6,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'hous',\n",
            "                                        'pin',\n",
            "                                        'opportunities',\n",
            "                                        'wonder',\n",
            "                                        'peter',\n",
            "                                        'prolong',\n",
            "                                        'match',\n",
            "                                        'wiz',\n",
            "                                        'wildlife',\n",
            "                                        'journal'],\n",
            "                      'similar_words': [ 'move',\n",
            "                                         'talking',\n",
            "                                         'talk',\n",
            "                                         'edge',\n",
            "                                         'cock',\n",
            "                                         'slant',\n",
            "                                         'slope',\n",
            "                                         'pitch',\n",
            "                                         'side',\n",
            "                                         'bank'],\n",
            "                      'word': 'cant'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 9,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'stead',\n",
            "                                        'canucks',\n",
            "                                        'trucks',\n",
            "                                        'ɮ',\n",
            "                                        'proxim',\n",
            "                                        'marit',\n",
            "                                        'prelimin',\n",
            "                                        'noted',\n",
            "                                        'johnny',\n",
            "                                        'bloody'],\n",
            "                      'similar_words': [ 'bear',\n",
            "                                         'exhaust',\n",
            "                                         'feature',\n",
            "                                         'break',\n",
            "                                         'wear',\n",
            "                                         'hat',\n",
            "                                         'bust',\n",
            "                                         'assume',\n",
            "                                         'don',\n",
            "                                         'decay'],\n",
            "                      'word': 'weares'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 4,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'roc',\n",
            "                                        'magic',\n",
            "                                        'verdict',\n",
            "                                        'metre',\n",
            "                                        'armenia',\n",
            "                                        'raising',\n",
            "                                        'ltd',\n",
            "                                        'gamb',\n",
            "                                        'document',\n",
            "                                        'mal'],\n",
            "                      'similar_words': [ 'lay',\n",
            "                                         'prepare',\n",
            "                                         'study',\n",
            "                                         'drum',\n",
            "                                         'ram',\n",
            "                                         'put',\n",
            "                                         'position',\n",
            "                                         'place',\n",
            "                                         'fix',\n",
            "                                         'stuff'],\n",
            "                      'word': 'crams'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 5,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'bitter',\n",
            "                                        'film',\n",
            "                                        'ste',\n",
            "                                        'pony',\n",
            "                                        'language',\n",
            "                                        'harvard',\n",
            "                                        'contempor',\n",
            "                                        'fan',\n",
            "                                        'highlights',\n",
            "                                        'finger'],\n",
            "                      'similar_words': [ 'captive',\n",
            "                                         'con',\n",
            "                                         'rig',\n",
            "                                         'rook',\n",
            "                                         'short',\n",
            "                                         'sting',\n",
            "                                         'learn',\n",
            "                                         'study',\n",
            "                                         'statement',\n",
            "                                         'prisoner'],\n",
            "                      'word': 'cons'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 4,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'ibn',\n",
            "                                        'constitu',\n",
            "                                        'traged',\n",
            "                                        'worn',\n",
            "                                        'ended',\n",
            "                                        'elder',\n",
            "                                        'poor',\n",
            "                                        'commanding',\n",
            "                                        'households',\n",
            "                                        'learned'],\n",
            "                      'similar_words': [ 'vamp',\n",
            "                                         'point',\n",
            "                                         'patch',\n",
            "                                         'piece',\n",
            "                                         'reconstruction',\n",
            "                                         'repair',\n",
            "                                         'amend',\n",
            "                                         'improve',\n",
            "                                         'better',\n",
            "                                         'care'],\n",
            "                      'word': 'mend'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 3,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'η',\n",
            "                                        'decide',\n",
            "                                        'facult',\n",
            "                                        'scholars',\n",
            "                                        'flex',\n",
            "                                        'miz',\n",
            "                                        'radar',\n",
            "                                        'forec',\n",
            "                                        'nelson',\n",
            "                                        'dece'],\n",
            "                      'similar_words': [ 'replay',\n",
            "                                         'rag',\n",
            "                                         'line',\n",
            "                                         'channel',\n",
            "                                         'play',\n",
            "                                         'speak',\n",
            "                                         'repeat',\n",
            "                                         'jazz',\n",
            "                                         'riff',\n",
            "                                         'tongue'],\n",
            "                      'word': 'spiel'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 12,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'chandler',\n",
            "                                        'rig',\n",
            "                                        'paying',\n",
            "                                        'either',\n",
            "                                        'variations',\n",
            "                                        'exciting',\n",
            "                                        'fal',\n",
            "                                        'carlos',\n",
            "                                        'nest',\n",
            "                                        'euras'],\n",
            "                      'similar_words': [ 'ride',\n",
            "                                         'buck',\n",
            "                                         'stay',\n",
            "                                         'halt',\n",
            "                                         'interference',\n",
            "                                         'arrest',\n",
            "                                         'connect',\n",
            "                                         'catch',\n",
            "                                         'walk',\n",
            "                                         'period'],\n",
            "                      'word': 'hitch'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 5,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'incidents',\n",
            "                                        'antarctic',\n",
            "                                        'supposed',\n",
            "                                        'summon',\n",
            "                                        'miners',\n",
            "                                        'theatrical',\n",
            "                                        'emmy',\n",
            "                                        'alk',\n",
            "                                        'prolong',\n",
            "                                        'rosa'],\n",
            "                      'similar_words': [ 'area',\n",
            "                                         'place',\n",
            "                                         'heart',\n",
            "                                         'section',\n",
            "                                         'pose',\n",
            "                                         'midfield',\n",
            "                                         'lay',\n",
            "                                         'eye',\n",
            "                                         'point',\n",
            "                                         'put'],\n",
            "                      'word': 'middles'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'plant',\n",
            "                                        'its',\n",
            "                                        'consequences',\n",
            "                                        'writ',\n",
            "                                        'endangered',\n",
            "                                        'tribut',\n",
            "                                        'control',\n",
            "                                        'dover',\n",
            "                                        'aires',\n",
            "                                        'altogether'],\n",
            "                      'similar_words': [ 'doubles',\n",
            "                                         'singles',\n",
            "                                         'sport',\n",
            "                                         'duo',\n",
            "                                         'ball',\n",
            "                                         'net',\n",
            "                                         'court',\n",
            "                                         'serve',\n",
            "                                         'hit',\n",
            "                                         'smash'],\n",
            "                      'word': 'tennis'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'museums',\n",
            "                                        'ruler',\n",
            "                                        'rex',\n",
            "                                        'nomin',\n",
            "                                        'pres',\n",
            "                                        'cattle',\n",
            "                                        'cream',\n",
            "                                        'ber',\n",
            "                                        'overseas',\n",
            "                                        'admission'],\n",
            "                      'similar_words': [ 'recommend',\n",
            "                                         'push',\n",
            "                                         'measure',\n",
            "                                         'proclaim',\n",
            "                                         'assess',\n",
            "                                         'value',\n",
            "                                         'laud',\n",
            "                                         'praise',\n",
            "                                         'promote',\n",
            "                                         'worship'],\n",
            "                      'word': 'praised'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'lanes',\n",
            "                                        'opera',\n",
            "                                        'hierarch',\n",
            "                                        'eb',\n",
            "                                        'those',\n",
            "                                        'crystall',\n",
            "                                        'repeat',\n",
            "                                        'specialized',\n",
            "                                        'dat',\n",
            "                                        'weekly'],\n",
            "                      'similar_words': [ 'success',\n",
            "                                         'sweep',\n",
            "                                         'finish',\n",
            "                                         'slam',\n",
            "                                         'pin',\n",
            "                                         'win',\n",
            "                                         'triumph',\n",
            "                                         'ending',\n",
            "                                         'fall',\n",
            "                                         'conclusion'],\n",
            "                      'word': 'victory'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'lia',\n",
            "                                        'sierra',\n",
            "                                        'peers',\n",
            "                                        'surface',\n",
            "                                        'bever',\n",
            "                                        'mother',\n",
            "                                        'bapt',\n",
            "                                        'hack',\n",
            "                                        'trend',\n",
            "                                        'overnight'],\n",
            "                      'similar_words': [ 'order',\n",
            "                                         'chapter',\n",
            "                                         'club',\n",
            "                                         'association',\n",
            "                                         'hunt',\n",
            "                                         'lodge',\n",
            "                                         'society',\n",
            "                                         'group',\n",
            "                                         'members',\n",
            "                                         'union'],\n",
            "                      'word': 'guild'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 2,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'incorpor',\n",
            "                                        'ancestors',\n",
            "                                        'debated',\n",
            "                                        're',\n",
            "                                        'operator',\n",
            "                                        'math',\n",
            "                                        'hydro',\n",
            "                                        'neutral',\n",
            "                                        'competition',\n",
            "                                        'interc'],\n",
            "                      'similar_words': [ 'component',\n",
            "                                         'feature',\n",
            "                                         'part',\n",
            "                                         'micro',\n",
            "                                         'compact',\n",
            "                                         'magnitude',\n",
            "                                         'scale',\n",
            "                                         'size',\n",
            "                                         'tiny',\n",
            "                                         'small'],\n",
            "                      'word': 'mini'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'vic',\n",
            "                                        'superhero',\n",
            "                                        'travelled',\n",
            "                                        'у',\n",
            "                                        'farms',\n",
            "                                        'youn',\n",
            "                                        'client',\n",
            "                                        'ship',\n",
            "                                        'inf',\n",
            "                                        'hero'],\n",
            "                      'similar_words': [ 'realize',\n",
            "                                         'earn',\n",
            "                                         'clear',\n",
            "                                         'make',\n",
            "                                         'gross',\n",
            "                                         'gain',\n",
            "                                         'income',\n",
            "                                         'sales',\n",
            "                                         'revenue',\n",
            "                                         'profit'],\n",
            "                      'word': 'grossing'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'control',\n",
            "                                        'espn',\n",
            "                                        'mountains',\n",
            "                                        'disk',\n",
            "                                        'pend',\n",
            "                                        'nashville',\n",
            "                                        'food',\n",
            "                                        'identify',\n",
            "                                        'academic',\n",
            "                                        'redes'],\n",
            "                      'similar_words': [ 'freeway',\n",
            "                                         'interstate',\n",
            "                                         'motorway',\n",
            "                                         'bypass',\n",
            "                                         'pike',\n",
            "                                         'road',\n",
            "                                         'expressway',\n",
            "                                         'route',\n",
            "                                         'realize',\n",
            "                                         'car'],\n",
            "                      'word': 'highway'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'ritual',\n",
            "                                        'ɣ',\n",
            "                                        'amazing',\n",
            "                                        'ecosystem',\n",
            "                                        'portuguese',\n",
            "                                        'malcolm',\n",
            "                                        'bot',\n",
            "                                        'chart',\n",
            "                                        'ly',\n",
            "                                        'stalin'],\n",
            "                      'similar_words': [ 'broadcast',\n",
            "                                         'send',\n",
            "                                         'air',\n",
            "                                         'beam',\n",
            "                                         'news',\n",
            "                                         'anchor',\n",
            "                                         'screen',\n",
            "                                         'media',\n",
            "                                         'live',\n",
            "                                         'communication'],\n",
            "                      'word': 'televised'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 3,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'coin',\n",
            "                                        'review',\n",
            "                                        'determ',\n",
            "                                        'sydney',\n",
            "                                        'ruins',\n",
            "                                        'ded',\n",
            "                                        'pharm',\n",
            "                                        'thompson',\n",
            "                                        'liquid',\n",
            "                                        'vital'],\n",
            "                      'similar_words': [ 'supposed',\n",
            "                                         'assert',\n",
            "                                         'say',\n",
            "                                         'aver',\n",
            "                                         'maintain',\n",
            "                                         'victim',\n",
            "                                         'report',\n",
            "                                         'crime',\n",
            "                                         'statement',\n",
            "                                         'claim'],\n",
            "                      'word': 'alleged'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'missionary',\n",
            "                                        'blocks',\n",
            "                                        'bull',\n",
            "                                        'sport',\n",
            "                                        'withdrew',\n",
            "                                        'destroyers',\n",
            "                                        'arb',\n",
            "                                        'missiles',\n",
            "                                        'scully',\n",
            "                                        'one'],\n",
            "                      'similar_words': [ 'virtually',\n",
            "                                         'about',\n",
            "                                         'most',\n",
            "                                         'nearly',\n",
            "                                         'near',\n",
            "                                         'closely',\n",
            "                                         'around',\n",
            "                                         'degree',\n",
            "                                         'approximately',\n",
            "                                         'roughly'],\n",
            "                      'word': 'almost'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'thrust',\n",
            "                                        'tale',\n",
            "                                        'desired',\n",
            "                                        'increased',\n",
            "                                        'stabil',\n",
            "                                        'illustrations',\n",
            "                                        'era',\n",
            "                                        'touchdowns',\n",
            "                                        'enforcement',\n",
            "                                        'red'],\n",
            "                      'similar_words': [ 'curse',\n",
            "                                         'official',\n",
            "                                         'criticism',\n",
            "                                         'opinion',\n",
            "                                         'charges',\n",
            "                                         'report',\n",
            "                                         'reject',\n",
            "                                         'declaration',\n",
            "                                         'public',\n",
            "                                         'statement'],\n",
            "                      'word': 'denouncements'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'perception',\n",
            "                                        'bost',\n",
            "                                        'laure',\n",
            "                                        'declaring',\n",
            "                                        'group',\n",
            "                                        'soph',\n",
            "                                        'possess',\n",
            "                                        'evidence',\n",
            "                                        'fragments',\n",
            "                                        'cluster'],\n",
            "                      'similar_words': [ 'money',\n",
            "                                         'debt',\n",
            "                                         'credit',\n",
            "                                         'bank',\n",
            "                                         'contract',\n",
            "                                         'invest',\n",
            "                                         'property',\n",
            "                                         'loan',\n",
            "                                         'interest',\n",
            "                                         'lend'],\n",
            "                      'word': 'mortgagee'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'statement',\n",
            "                                        'home',\n",
            "                                        'pomp',\n",
            "                                        'yield',\n",
            "                                        'triggered',\n",
            "                                        'understanding',\n",
            "                                        'citing',\n",
            "                                        'pand',\n",
            "                                        'bout',\n",
            "                                        'claimed'],\n",
            "                      'similar_words': [ 'have',\n",
            "                                         'pair',\n",
            "                                         'jazz',\n",
            "                                         'bed',\n",
            "                                         'fuck',\n",
            "                                         'mate',\n",
            "                                         'love',\n",
            "                                         'know',\n",
            "                                         'bang',\n",
            "                                         'couple'],\n",
            "                      'word': 'eff'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'persuade',\n",
            "                                        'survived',\n",
            "                                        'tornado',\n",
            "                                        'arriving',\n",
            "                                        'static',\n",
            "                                        'israel',\n",
            "                                        'persian',\n",
            "                                        'ol',\n",
            "                                        'capability',\n",
            "                                        'years'],\n",
            "                      'similar_words': [ 'drugs',\n",
            "                                         'chemical',\n",
            "                                         'experiment',\n",
            "                                         'doctor',\n",
            "                                         'medicine',\n",
            "                                         'company',\n",
            "                                         'industry',\n",
            "                                         'health',\n",
            "                                         'laboratory',\n",
            "                                         'trials'],\n",
            "                      'word': 'pharmacologists'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'les',\n",
            "                                        'resident',\n",
            "                                        'fun',\n",
            "                                        'po',\n",
            "                                        'britney',\n",
            "                                        'episode',\n",
            "                                        'requ',\n",
            "                                        'freder',\n",
            "                                        'nort',\n",
            "                                        'vot'],\n",
            "                      'similar_words': [ 'anatomy',\n",
            "                                         'figure',\n",
            "                                         'shape',\n",
            "                                         'form',\n",
            "                                         'person',\n",
            "                                         'flesh',\n",
            "                                         'frame',\n",
            "                                         'body',\n",
            "                                         'build',\n",
            "                                         'physical'],\n",
            "                      'word': 'bod'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'associ',\n",
            "                                        'primarily',\n",
            "                                        'sig',\n",
            "                                        'tourism',\n",
            "                                        'andre',\n",
            "                                        'demolished',\n",
            "                                        'terr',\n",
            "                                        'duration',\n",
            "                                        'somet',\n",
            "                                        'act'],\n",
            "                      'similar_words': [ 'let',\n",
            "                                         'allow',\n",
            "                                         'permit',\n",
            "                                         'legitimate',\n",
            "                                         'enact',\n",
            "                                         'license',\n",
            "                                         'statute',\n",
            "                                         'act',\n",
            "                                         'law',\n",
            "                                         'authority'],\n",
            "                      'word': 'legalises'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'forests',\n",
            "                                        'warrior',\n",
            "                                        'neighbour',\n",
            "                                        'conning',\n",
            "                                        'colors',\n",
            "                                        'charl',\n",
            "                                        'garnered',\n",
            "                                        'manu',\n",
            "                                        'phenom',\n",
            "                                        'somerset'],\n",
            "                      'similar_words': [ 'meet',\n",
            "                                         'fit',\n",
            "                                         'merit',\n",
            "                                         'advantage',\n",
            "                                         'require',\n",
            "                                         'responsibility',\n",
            "                                         'duty',\n",
            "                                         'suit',\n",
            "                                         'benefit',\n",
            "                                         'serve'],\n",
            "                      'word': 'behoove'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'lower',\n",
            "                                        'finals',\n",
            "                                        'diseas',\n",
            "                                        'revision',\n",
            "                                        'morton',\n",
            "                                        'jess',\n",
            "                                        'pow',\n",
            "                                        'substance',\n",
            "                                        'fib',\n",
            "                                        'proximity'],\n",
            "                      'similar_words': [ 'alter',\n",
            "                                         'change',\n",
            "                                         'villain',\n",
            "                                         'attack',\n",
            "                                         'criticism',\n",
            "                                         'abuse',\n",
            "                                         'reputation',\n",
            "                                         'character',\n",
            "                                         'image',\n",
            "                                         'opinion'],\n",
            "                      'word': 'demonise'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'brooks',\n",
            "                                        'oppon',\n",
            "                                        'determine',\n",
            "                                        'millimet',\n",
            "                                        'does',\n",
            "                                        'ende',\n",
            "                                        'anticipated',\n",
            "                                        'innovation',\n",
            "                                        'jen',\n",
            "                                        'accept'],\n",
            "                      'similar_words': [ 'trade',\n",
            "                                         'interact',\n",
            "                                         'bank',\n",
            "                                         'sell',\n",
            "                                         'deal',\n",
            "                                         'goods',\n",
            "                                         'buy',\n",
            "                                         'machine',\n",
            "                                         'partner',\n",
            "                                         'money'],\n",
            "                      'word': 'transact'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'exhibition',\n",
            "                                        'creek',\n",
            "                                        'potter',\n",
            "                                        'unsuccessful',\n",
            "                                        'trunk',\n",
            "                                        'buying',\n",
            "                                        'entry',\n",
            "                                        'nh',\n",
            "                                        'off',\n",
            "                                        'northumb'],\n",
            "                      'similar_words': [ 'regard',\n",
            "                                         'view',\n",
            "                                         'consider',\n",
            "                                         'hold',\n",
            "                                         'see',\n",
            "                                         'rate',\n",
            "                                         'thought',\n",
            "                                         'mind',\n",
            "                                         'believe',\n",
            "                                         'judge'],\n",
            "                      'word': 'deem'}]}\n"
          ]
        }
      ],
      "source": [
        "vocab_file = \"vocab.txt\"\n",
        "bert_vocab = set()\n",
        "\n",
        "with open(vocab_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        token = line.strip()\n",
        "        if token.isalpha() and token.islower():\n",
        "            bert_vocab.add(token)\n",
        "\n",
        "print(f\"Loaded {len(bert_vocab)} BERT vocab words.\")\n",
        "\n",
        "dataset = load_dataset(\"wikitext\", \"wikitext-103-v1\")\n",
        "texts = dataset[\"train\"][\"text\"]\n",
        "\n",
        "dataset_vocab = set()\n",
        "for line in texts:\n",
        "    tokens = line.split()\n",
        "    for token in tokens:\n",
        "        if token.isalpha() and token.islower():\n",
        "            dataset_vocab.add(token.lower())\n",
        "\n",
        "dataset_vocab = list(dataset_vocab)\n",
        "\n",
        "poly_freq = [\"break\", \"cut\", \"running\", \"play\", \"make\", \"better\",\n",
        "             \"light\", \"falls\", \"clear\", \"open\"]\n",
        "\n",
        "poly_infreq = [\"ply\", \"vamp\", \"cant\", \"weares\", \"crams\",\n",
        "               \"cons\", \"mend\", \"spiel\", \"hitch\", \"middles\"]\n",
        "\n",
        "mono_freq = [\"tennis\", \"praised\", \"victory\", \"guild\", \"mini\", \"grossing\",\n",
        "             \"highway\", \"televised\", \"alleged\", \"almost\"]\n",
        "\n",
        "mono_infreq = [\"denouncements\", \"mortgagee\", \"eff\", \"pharmacologists\",\n",
        "               \"bod\", \"legalises\", \"behoove\", \"demonise\", \"transact\", \"deem\"]\n",
        "\n",
        "target_words_list = set(poly_freq + poly_infreq + mono_freq + mono_infreq)\n",
        "\n",
        "def get_num_senses(word):\n",
        "    \"\"\"Return number of WordNet synsets for a word.\"\"\"\n",
        "    return len(wn.synsets(word))\n",
        "\n",
        "def get_similar_words_wordnet_only(word, max_results=10):\n",
        "    \"\"\"Return WordNet-based similar words filtered by BERT vocab.\"\"\"\n",
        "    word_lower = word.lower()\n",
        "    related = set()\n",
        "\n",
        "    for syn in wn.synsets(word_lower):\n",
        "        for lemma in syn.lemmas():\n",
        "            related.add(lemma.name().lower())\n",
        "        for hyper in syn.hypernyms():\n",
        "            for lemma in hyper.lemmas():\n",
        "                related.add(lemma.name().lower())\n",
        "        for hypo in syn.hyponyms():\n",
        "            for lemma in hypo.lemmas():\n",
        "                related.add(lemma.name().lower())\n",
        "\n",
        "    related.discard(word_lower)\n",
        "\n",
        "    filtered = [w for w in related if w in bert_vocab]\n",
        "    random.shuffle(filtered)\n",
        "    return filtered[:max_results]\n",
        "\n",
        "def ensure_ten_similar_words(similar_words, word):\n",
        "    \"\"\"Ensure similar_words has 10 entries; ask user to add more if needed.\"\"\"\n",
        "    while len(similar_words) < 10:\n",
        "        print(f\"\\nThe word '{word}' has only {len(similar_words)} similar words:\")\n",
        "        print(similar_words)\n",
        "        user_input = input(f\"Add an additional similar word for '{word}': \").strip().lower()\n",
        "        if user_input in bert_vocab and user_input not in similar_words:\n",
        "            similar_words.append(user_input)\n",
        "            print(f\"Added '{user_input}' to similar_words.\")\n",
        "        else:\n",
        "            print(f\"'{user_input}' is not in BERT vocab or already in the list. Try again.\")\n",
        "    return similar_words\n",
        "\n",
        "def get_random_words_from_bert_vocab(exclude_words, num_words=10):\n",
        "    \"\"\"Return random words from BERT vocab excluding target words.\"\"\"\n",
        "    candidates = list(bert_vocab - set(exclude_words))\n",
        "    return random.sample(candidates, min(num_words, len(candidates)))\n",
        "\n",
        "def add_words(word_list, freq_class, poly_class, target_words_set):\n",
        "    entries = []\n",
        "    for word in word_list:\n",
        "        similar = get_similar_words_wordnet_only(word, 10)\n",
        "        similar = ensure_ten_similar_words(similar, word)\n",
        "\n",
        "        entry = {\n",
        "            \"word\": word,\n",
        "            \"frequency_class\": freq_class,\n",
        "            \"polysemy_class\": poly_class,\n",
        "            \"num_senses\": get_num_senses(word),\n",
        "            \"similar_words\": similar,\n",
        "            \"random_words\": get_random_words_from_bert_vocab(target_words_set.union({word.lower()}), 10)\n",
        "        }\n",
        "        entries.append(entry)\n",
        "    return entries\n",
        "\n",
        "\n",
        "mock_dataset = {\"target_words\": []}\n",
        "mock_dataset[\"target_words\"].extend(add_words(poly_freq, \"frequent\", \"polysemous\", target_words_list))\n",
        "mock_dataset[\"target_words\"].extend(add_words(poly_infreq, \"infrequent\", \"polysemous\", target_words_list))\n",
        "mock_dataset[\"target_words\"].extend(add_words(mono_freq, \"frequent\", \"monosemous\", target_words_list))\n",
        "mock_dataset[\"target_words\"].extend(add_words(mono_infreq, \"infrequent\", \"monosemous\", target_words_list))\n",
        "\n",
        "pp = pprint.PrettyPrinter(indent=2, width=120)\n",
        "pp.pprint(mock_dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Replacing the random words to use in vocab real words"
      ],
      "metadata": {
        "id": "K9Z4TY2Vwig7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_file = \"vocab.txt\"\n",
        "bert_vocab_raw = []\n",
        "\n",
        "with open(vocab_file, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        token = line.strip()\n",
        "        bert_vocab_raw.append(token)\n",
        "\n",
        "print(f\"Total tokens in vocab file: {len(bert_vocab_raw)}\")\n",
        "\n",
        "wn_lemmas = set()\n",
        "for syn in wn.all_synsets():\n",
        "    for lemma in syn.lemmas():\n",
        "        wn_lemmas.add(lemma.name().lower())\n",
        "\n",
        "def is_valid_word(token):\n",
        "    if not token:\n",
        "        return False\n",
        "    if token.startswith(\"##\"):\n",
        "        return False\n",
        "    if not token.isalpha():\n",
        "        return False\n",
        "    if token != token.lower():\n",
        "        return False\n",
        "    if len(token) < 3:\n",
        "        return False\n",
        "    if token not in wn_lemmas:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "bert_vocab = {t for t in bert_vocab_raw if is_valid_word(t)}\n",
        "print(f\"Filtered real-word BERT vocab size: {len(bert_vocab)}\")\n",
        "\n",
        "def get_random_words_from_bert_vocab(exclude_words, num_words=10):\n",
        "    \"\"\"Return random full words from BERT vocab excluding target words.\"\"\"\n",
        "    exclude_set = set(w.lower() for w in exclude_words)\n",
        "    candidates = [w for w in bert_vocab if w not in exclude_set]\n",
        "\n",
        "    if len(candidates) < num_words:\n",
        "        candidates = [w for w in bert_vocab_raw\n",
        "                      if w.isalpha() and w.islower() and not w.startswith(\"##\")\n",
        "                      and len(w) >= 3 and w not in exclude_set]\n",
        "    return random.sample(candidates, min(num_words, len(candidates)))\n",
        "\n",
        "for entry in mock_dataset.get(\"target_words\", []):\n",
        "    exclude = set(x.lower() for x in target_words_list)\n",
        "    exclude.add(entry[\"word\"].lower())\n",
        "    entry[\"random_words\"] = get_random_words_from_bert_vocab(exclude, 10)\n",
        "\n",
        "pp = pprint.PrettyPrinter(indent=2, width=100)\n",
        "pp.pprint(mock_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCyrCmd9Zwf_",
        "outputId": "6c2bcb61-9d16-48a7-e39c-4749ad2c70e3"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total tokens in vocab file: 16384\n",
            "Filtered real-word BERT vocab size: 6657\n",
            "{ 'target_words': [ { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 75,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'anne',\n",
            "                                        'scar',\n",
            "                                        'cold',\n",
            "                                        'drought',\n",
            "                                        'matthew',\n",
            "                                        'stuff',\n",
            "                                        'establish',\n",
            "                                        'collected',\n",
            "                                        'crossed',\n",
            "                                        'promising'],\n",
            "                      'similar_words': [ 'hurt',\n",
            "                                         'divide',\n",
            "                                         'dance',\n",
            "                                         'work',\n",
            "                                         'exchange',\n",
            "                                         'blow',\n",
            "                                         'damage',\n",
            "                                         'harm',\n",
            "                                         'talk',\n",
            "                                         'better'],\n",
            "                      'word': 'break'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 70,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'draft',\n",
            "                                        'ended',\n",
            "                                        'dropping',\n",
            "                                        'asian',\n",
            "                                        'quit',\n",
            "                                        'med',\n",
            "                                        'favor',\n",
            "                                        'terrible',\n",
            "                                        'credits',\n",
            "                                        'expressway'],\n",
            "                      'similar_words': [ 'rib',\n",
            "                                         'tap',\n",
            "                                         'transit',\n",
            "                                         'shot',\n",
            "                                         'crop',\n",
            "                                         'hob',\n",
            "                                         'create',\n",
            "                                         'opening',\n",
            "                                         'resolve',\n",
            "                                         'chase'],\n",
            "                      'word': 'cut'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 52,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'faction',\n",
            "                                        'extinct',\n",
            "                                        'green',\n",
            "                                        'branch',\n",
            "                                        'circuit',\n",
            "                                        'dec',\n",
            "                                        'iraq',\n",
            "                                        'rous',\n",
            "                                        'fourteenth',\n",
            "                                        'telling'],\n",
            "                      'similar_words': [ 'speed',\n",
            "                                         'flow',\n",
            "                                         'rushing',\n",
            "                                         'release',\n",
            "                                         'campaign',\n",
            "                                         'carry',\n",
            "                                         'succeed',\n",
            "                                         'trade',\n",
            "                                         'lean',\n",
            "                                         'rub'],\n",
            "                      'word': 'running'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 52,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'chapter',\n",
            "                                        'expect',\n",
            "                                        'determination',\n",
            "                                        'accurate',\n",
            "                                        'halo',\n",
            "                                        'curve',\n",
            "                                        'solo',\n",
            "                                        'todd',\n",
            "                                        'relative',\n",
            "                                        'president'],\n",
            "                      'similar_words': [ 'parody',\n",
            "                                         'beat',\n",
            "                                         'ham',\n",
            "                                         'perform',\n",
            "                                         'walk',\n",
            "                                         'exercise',\n",
            "                                         'die',\n",
            "                                         'retire',\n",
            "                                         'shot',\n",
            "                                         'doctor'],\n",
            "                      'word': 'play'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 51,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'truman',\n",
            "                                        'windsor',\n",
            "                                        'rhythm',\n",
            "                                        'possibility',\n",
            "                                        'junior',\n",
            "                                        'plane',\n",
            "                                        'sword',\n",
            "                                        'mob',\n",
            "                                        'exception',\n",
            "                                        'satisfied'],\n",
            "                      'similar_words': [ 'render',\n",
            "                                         'elaborate',\n",
            "                                         'cut',\n",
            "                                         'pull',\n",
            "                                         'gross',\n",
            "                                         'number',\n",
            "                                         'incorporate',\n",
            "                                         'take',\n",
            "                                         'leave',\n",
            "                                         'be'],\n",
            "                      'word': 'make'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 50,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'end',\n",
            "                                        'construction',\n",
            "                                        'rosa',\n",
            "                                        'closest',\n",
            "                                        'motif',\n",
            "                                        'servant',\n",
            "                                        'gulf',\n",
            "                                        'morn',\n",
            "                                        'funk',\n",
            "                                        'mortar'],\n",
            "                      'similar_words': [ 'break',\n",
            "                                         'substantially',\n",
            "                                         'well',\n",
            "                                         'surge',\n",
            "                                         'raise',\n",
            "                                         'down',\n",
            "                                         'surpass',\n",
            "                                         'near',\n",
            "                                         'recover',\n",
            "                                         'upgrade'],\n",
            "                      'word': 'better'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 47,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'eat',\n",
            "                                        'hob',\n",
            "                                        'offering',\n",
            "                                        'like',\n",
            "                                        'mild',\n",
            "                                        'tiny',\n",
            "                                        'purely',\n",
            "                                        'relative',\n",
            "                                        'exceptional',\n",
            "                                        'grand'],\n",
            "                      'similar_words': [ 'meteor',\n",
            "                                         'status',\n",
            "                                         'expression',\n",
            "                                         'flood',\n",
            "                                         'glory',\n",
            "                                         'weak',\n",
            "                                         'condition',\n",
            "                                         'perspective',\n",
            "                                         'clear',\n",
            "                                         'lighter'],\n",
            "                      'word': 'light'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 46,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'address',\n",
            "                                        'iceland',\n",
            "                                        'pointed',\n",
            "                                        'radiation',\n",
            "                                        'solution',\n",
            "                                        'teen',\n",
            "                                        'forward',\n",
            "                                        'slip',\n",
            "                                        'premise',\n",
            "                                        'chambers'],\n",
            "                      'similar_words': [ 'begin',\n",
            "                                         'descend',\n",
            "                                         'precipitation',\n",
            "                                         'hail',\n",
            "                                         'slow',\n",
            "                                         'twilight',\n",
            "                                         'pin',\n",
            "                                         'pass',\n",
            "                                         'travel',\n",
            "                                         'weakening'],\n",
            "                      'word': 'falls'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 45,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'cowboy',\n",
            "                                        'grim',\n",
            "                                        'supporting',\n",
            "                                        'cry',\n",
            "                                        'flat',\n",
            "                                        'particular',\n",
            "                                        'reconstruction',\n",
            "                                        'beaut',\n",
            "                                        'gaming',\n",
            "                                        'remarkable'],\n",
            "                      'similar_words': [ 'permit',\n",
            "                                         'label',\n",
            "                                         'alter',\n",
            "                                         'remove',\n",
            "                                         'free',\n",
            "                                         'create',\n",
            "                                         'take',\n",
            "                                         'acquire',\n",
            "                                         'top',\n",
            "                                         'clean'],\n",
            "                      'word': 'clear'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 36,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'paul',\n",
            "                                        'museum',\n",
            "                                        'objective',\n",
            "                                        'brazil',\n",
            "                                        'difficult',\n",
            "                                        'pin',\n",
            "                                        'cylinder',\n",
            "                                        'enclosed',\n",
            "                                        'court',\n",
            "                                        'alarm'],\n",
            "                      'similar_words': [ 'butterfly',\n",
            "                                         'exhibit',\n",
            "                                         'grass',\n",
            "                                         'clear',\n",
            "                                         'display',\n",
            "                                         'turn',\n",
            "                                         'spread',\n",
            "                                         'candid',\n",
            "                                         'start',\n",
            "                                         'country'],\n",
            "                      'word': 'open'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 8,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'township',\n",
            "                                        'candid',\n",
            "                                        'fit',\n",
            "                                        'celebrity',\n",
            "                                        'material',\n",
            "                                        'sustained',\n",
            "                                        'are',\n",
            "                                        'electronics',\n",
            "                                        'acting',\n",
            "                                        'bridge'],\n",
            "                      'similar_words': [ 'apply',\n",
            "                                         'cater',\n",
            "                                         'help',\n",
            "                                         'manage',\n",
            "                                         'run',\n",
            "                                         'employ',\n",
            "                                         'give',\n",
            "                                         'bed',\n",
            "                                         'travel',\n",
            "                                         'meet'],\n",
            "                      'word': 'ply'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 7,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'kentucky',\n",
            "                                        'stair',\n",
            "                                        'lab',\n",
            "                                        'mar',\n",
            "                                        'shale',\n",
            "                                        'pitcher',\n",
            "                                        'impossible',\n",
            "                                        'gary',\n",
            "                                        'alongside',\n",
            "                                        'castro'],\n",
            "                      'similar_words': [ 'mend',\n",
            "                                         'doctor',\n",
            "                                         'restore',\n",
            "                                         'manufacture',\n",
            "                                         'butterfly',\n",
            "                                         'support',\n",
            "                                         'patch',\n",
            "                                         'fix',\n",
            "                                         'backup',\n",
            "                                         'woman'],\n",
            "                      'word': 'vamp'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 6,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'notable',\n",
            "                                        'slav',\n",
            "                                        'four',\n",
            "                                        'innovation',\n",
            "                                        'brood',\n",
            "                                        'previous',\n",
            "                                        'chapman',\n",
            "                                        'rend',\n",
            "                                        'preserve',\n",
            "                                        'impression'],\n",
            "                      'similar_words': [ 'move',\n",
            "                                         'talking',\n",
            "                                         'talk',\n",
            "                                         'edge',\n",
            "                                         'cock',\n",
            "                                         'slant',\n",
            "                                         'slope',\n",
            "                                         'pitch',\n",
            "                                         'side',\n",
            "                                         'bank'],\n",
            "                      'word': 'cant'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 9,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'trust',\n",
            "                                        'orthodox',\n",
            "                                        'bottle',\n",
            "                                        'influence',\n",
            "                                        'loading',\n",
            "                                        'mother',\n",
            "                                        'franc',\n",
            "                                        'planning',\n",
            "                                        'portable',\n",
            "                                        'dual'],\n",
            "                      'similar_words': [ 'bear',\n",
            "                                         'exhaust',\n",
            "                                         'feature',\n",
            "                                         'break',\n",
            "                                         'wear',\n",
            "                                         'hat',\n",
            "                                         'bust',\n",
            "                                         'assume',\n",
            "                                         'don',\n",
            "                                         'decay'],\n",
            "                      'word': 'weares'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 4,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'soviets',\n",
            "                                        'operation',\n",
            "                                        'selling',\n",
            "                                        'glory',\n",
            "                                        'fielding',\n",
            "                                        'meeting',\n",
            "                                        'rhythm',\n",
            "                                        'drop',\n",
            "                                        'each',\n",
            "                                        'normally'],\n",
            "                      'similar_words': [ 'lay',\n",
            "                                         'prepare',\n",
            "                                         'study',\n",
            "                                         'drum',\n",
            "                                         'ram',\n",
            "                                         'put',\n",
            "                                         'position',\n",
            "                                         'place',\n",
            "                                         'fix',\n",
            "                                         'stuff'],\n",
            "                      'word': 'crams'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 5,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'environmental',\n",
            "                                        'links',\n",
            "                                        'ancient',\n",
            "                                        'dol',\n",
            "                                        'arts',\n",
            "                                        'web',\n",
            "                                        'late',\n",
            "                                        'arthur',\n",
            "                                        'chen',\n",
            "                                        'positive'],\n",
            "                      'similar_words': [ 'captive',\n",
            "                                         'con',\n",
            "                                         'rig',\n",
            "                                         'rook',\n",
            "                                         'short',\n",
            "                                         'sting',\n",
            "                                         'learn',\n",
            "                                         'study',\n",
            "                                         'statement',\n",
            "                                         'prisoner'],\n",
            "                      'word': 'cons'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 4,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'uncertain',\n",
            "                                        'anime',\n",
            "                                        'west',\n",
            "                                        'attack',\n",
            "                                        'beneath',\n",
            "                                        'lab',\n",
            "                                        'personal',\n",
            "                                        'campus',\n",
            "                                        'decor',\n",
            "                                        'prefer'],\n",
            "                      'similar_words': [ 'vamp',\n",
            "                                         'point',\n",
            "                                         'patch',\n",
            "                                         'piece',\n",
            "                                         'reconstruction',\n",
            "                                         'repair',\n",
            "                                         'amend',\n",
            "                                         'improve',\n",
            "                                         'better',\n",
            "                                         'care'],\n",
            "                      'word': 'mend'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 3,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'framework',\n",
            "                                        'staff',\n",
            "                                        'inst',\n",
            "                                        'mayor',\n",
            "                                        'missile',\n",
            "                                        'huge',\n",
            "                                        'hood',\n",
            "                                        'logo',\n",
            "                                        'recruit',\n",
            "                                        'billed'],\n",
            "                      'similar_words': [ 'replay',\n",
            "                                         'rag',\n",
            "                                         'line',\n",
            "                                         'channel',\n",
            "                                         'play',\n",
            "                                         'speak',\n",
            "                                         'repeat',\n",
            "                                         'jazz',\n",
            "                                         'riff',\n",
            "                                         'tongue'],\n",
            "                      'word': 'spiel'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 12,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'pursuing',\n",
            "                                        'offensive',\n",
            "                                        'victorious',\n",
            "                                        'liner',\n",
            "                                        'drew',\n",
            "                                        'example',\n",
            "                                        'portrayed',\n",
            "                                        'orient',\n",
            "                                        'private',\n",
            "                                        'uprising'],\n",
            "                      'similar_words': [ 'ride',\n",
            "                                         'buck',\n",
            "                                         'stay',\n",
            "                                         'halt',\n",
            "                                         'interference',\n",
            "                                         'arrest',\n",
            "                                         'connect',\n",
            "                                         'catch',\n",
            "                                         'walk',\n",
            "                                         'period'],\n",
            "                      'word': 'hitch'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 5,\n",
            "                      'polysemy_class': 'polysemous',\n",
            "                      'random_words': [ 'couple',\n",
            "                                        'wool',\n",
            "                                        'write',\n",
            "                                        'detroit',\n",
            "                                        'killer',\n",
            "                                        'tape',\n",
            "                                        'mott',\n",
            "                                        'imagination',\n",
            "                                        'joke',\n",
            "                                        'valuable'],\n",
            "                      'similar_words': [ 'area',\n",
            "                                         'place',\n",
            "                                         'heart',\n",
            "                                         'section',\n",
            "                                         'pose',\n",
            "                                         'midfield',\n",
            "                                         'lay',\n",
            "                                         'eye',\n",
            "                                         'point',\n",
            "                                         'put'],\n",
            "                      'word': 'middles'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'pilot',\n",
            "                                        'surprise',\n",
            "                                        'automobile',\n",
            "                                        'partnership',\n",
            "                                        'pollution',\n",
            "                                        'montgomery',\n",
            "                                        'percent',\n",
            "                                        'attendance',\n",
            "                                        'hem',\n",
            "                                        'nec'],\n",
            "                      'similar_words': [ 'doubles',\n",
            "                                         'singles',\n",
            "                                         'sport',\n",
            "                                         'duo',\n",
            "                                         'ball',\n",
            "                                         'net',\n",
            "                                         'court',\n",
            "                                         'serve',\n",
            "                                         'hit',\n",
            "                                         'smash'],\n",
            "                      'word': 'tennis'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'leo',\n",
            "                                        'lengthy',\n",
            "                                        'helium',\n",
            "                                        'prompting',\n",
            "                                        'protective',\n",
            "                                        'boot',\n",
            "                                        'toronto',\n",
            "                                        'viking',\n",
            "                                        'advisory',\n",
            "                                        'yet'],\n",
            "                      'similar_words': [ 'recommend',\n",
            "                                         'push',\n",
            "                                         'measure',\n",
            "                                         'proclaim',\n",
            "                                         'assess',\n",
            "                                         'value',\n",
            "                                         'laud',\n",
            "                                         'praise',\n",
            "                                         'promote',\n",
            "                                         'worship'],\n",
            "                      'word': 'praised'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'out',\n",
            "                                        'enl',\n",
            "                                        'montreal',\n",
            "                                        'granted',\n",
            "                                        'additionally',\n",
            "                                        'nashville',\n",
            "                                        'rad',\n",
            "                                        'maple',\n",
            "                                        'thorn',\n",
            "                                        'beaut'],\n",
            "                      'similar_words': [ 'success',\n",
            "                                         'sweep',\n",
            "                                         'finish',\n",
            "                                         'slam',\n",
            "                                         'pin',\n",
            "                                         'win',\n",
            "                                         'triumph',\n",
            "                                         'ending',\n",
            "                                         'fall',\n",
            "                                         'conclusion'],\n",
            "                      'word': 'victory'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'headquarters',\n",
            "                                        'interface',\n",
            "                                        'ace',\n",
            "                                        'hum',\n",
            "                                        'infrastructure',\n",
            "                                        'printing',\n",
            "                                        'disney',\n",
            "                                        'harrison',\n",
            "                                        'extinction',\n",
            "                                        'fresh'],\n",
            "                      'similar_words': [ 'order',\n",
            "                                         'chapter',\n",
            "                                         'club',\n",
            "                                         'association',\n",
            "                                         'hunt',\n",
            "                                         'lodge',\n",
            "                                         'society',\n",
            "                                         'group',\n",
            "                                         'members',\n",
            "                                         'union'],\n",
            "                      'word': 'guild'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 2,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'torn',\n",
            "                                        'storage',\n",
            "                                        'fourteenth',\n",
            "                                        'cancelled',\n",
            "                                        'structure',\n",
            "                                        'select',\n",
            "                                        'observe',\n",
            "                                        'papal',\n",
            "                                        'cab',\n",
            "                                        'kentucky'],\n",
            "                      'similar_words': [ 'component',\n",
            "                                         'feature',\n",
            "                                         'part',\n",
            "                                         'micro',\n",
            "                                         'compact',\n",
            "                                         'magnitude',\n",
            "                                         'scale',\n",
            "                                         'size',\n",
            "                                         'tiny',\n",
            "                                         'small'],\n",
            "                      'word': 'mini'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'recommend',\n",
            "                                        'psychology',\n",
            "                                        'liked',\n",
            "                                        'musical',\n",
            "                                        'glee',\n",
            "                                        'flower',\n",
            "                                        'spread',\n",
            "                                        'remains',\n",
            "                                        'emir',\n",
            "                                        'vinyl'],\n",
            "                      'similar_words': [ 'realize',\n",
            "                                         'earn',\n",
            "                                         'clear',\n",
            "                                         'make',\n",
            "                                         'gross',\n",
            "                                         'gain',\n",
            "                                         'income',\n",
            "                                         'sales',\n",
            "                                         'revenue',\n",
            "                                         'profit'],\n",
            "                      'word': 'grossing'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'believing',\n",
            "                                        'similarity',\n",
            "                                        'verse',\n",
            "                                        'subsidiary',\n",
            "                                        'proceed',\n",
            "                                        'critic',\n",
            "                                        'impressive',\n",
            "                                        'may',\n",
            "                                        'forgotten',\n",
            "                                        'anthem'],\n",
            "                      'similar_words': [ 'freeway',\n",
            "                                         'interstate',\n",
            "                                         'motorway',\n",
            "                                         'bypass',\n",
            "                                         'pike',\n",
            "                                         'road',\n",
            "                                         'expressway',\n",
            "                                         'route',\n",
            "                                         'realize',\n",
            "                                         'car'],\n",
            "                      'word': 'highway'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'anderson',\n",
            "                                        'recall',\n",
            "                                        'engine',\n",
            "                                        'composer',\n",
            "                                        'listen',\n",
            "                                        'discovery',\n",
            "                                        'bosnia',\n",
            "                                        'nun',\n",
            "                                        'blond',\n",
            "                                        'ignored'],\n",
            "                      'similar_words': [ 'broadcast',\n",
            "                                         'send',\n",
            "                                         'air',\n",
            "                                         'beam',\n",
            "                                         'news',\n",
            "                                         'anchor',\n",
            "                                         'screen',\n",
            "                                         'media',\n",
            "                                         'live',\n",
            "                                         'communication'],\n",
            "                      'word': 'televised'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 3,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'chick',\n",
            "                                        'committed',\n",
            "                                        'surprising',\n",
            "                                        'castro',\n",
            "                                        'maker',\n",
            "                                        'authentic',\n",
            "                                        'subway',\n",
            "                                        'stem',\n",
            "                                        'wood',\n",
            "                                        'valuable'],\n",
            "                      'similar_words': [ 'supposed',\n",
            "                                         'assert',\n",
            "                                         'say',\n",
            "                                         'aver',\n",
            "                                         'maintain',\n",
            "                                         'victim',\n",
            "                                         'report',\n",
            "                                         'crime',\n",
            "                                         'statement',\n",
            "                                         'claim'],\n",
            "                      'word': 'alleged'},\n",
            "                    { 'frequency_class': 'frequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'surpass',\n",
            "                                        'crowd',\n",
            "                                        'exhibit',\n",
            "                                        'hendrix',\n",
            "                                        'maintenance',\n",
            "                                        'least',\n",
            "                                        'india',\n",
            "                                        'seats',\n",
            "                                        'bass',\n",
            "                                        'performing'],\n",
            "                      'similar_words': [ 'virtually',\n",
            "                                         'about',\n",
            "                                         'most',\n",
            "                                         'nearly',\n",
            "                                         'near',\n",
            "                                         'closely',\n",
            "                                         'around',\n",
            "                                         'degree',\n",
            "                                         'approximately',\n",
            "                                         'roughly'],\n",
            "                      'word': 'almost'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'marc',\n",
            "                                        'medical',\n",
            "                                        'easter',\n",
            "                                        'registration',\n",
            "                                        'saudi',\n",
            "                                        'conservative',\n",
            "                                        'lead',\n",
            "                                        'outstanding',\n",
            "                                        'dynamic',\n",
            "                                        'alarm'],\n",
            "                      'similar_words': [ 'curse',\n",
            "                                         'official',\n",
            "                                         'criticism',\n",
            "                                         'opinion',\n",
            "                                         'charges',\n",
            "                                         'report',\n",
            "                                         'reject',\n",
            "                                         'declaration',\n",
            "                                         'public',\n",
            "                                         'statement'],\n",
            "                      'word': 'denouncements'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'copper',\n",
            "                                        'compton',\n",
            "                                        'correct',\n",
            "                                        'housing',\n",
            "                                        'safety',\n",
            "                                        'leeds',\n",
            "                                        'cinema',\n",
            "                                        'composer',\n",
            "                                        'regularly',\n",
            "                                        'dependent'],\n",
            "                      'similar_words': [ 'money',\n",
            "                                         'debt',\n",
            "                                         'credit',\n",
            "                                         'bank',\n",
            "                                         'contract',\n",
            "                                         'invest',\n",
            "                                         'property',\n",
            "                                         'loan',\n",
            "                                         'interest',\n",
            "                                         'lend'],\n",
            "                      'word': 'mortgagee'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'ale',\n",
            "                                        'soul',\n",
            "                                        'suspension',\n",
            "                                        'phon',\n",
            "                                        'regular',\n",
            "                                        'implement',\n",
            "                                        'framework',\n",
            "                                        'defender',\n",
            "                                        'readily',\n",
            "                                        'boiler'],\n",
            "                      'similar_words': [ 'have',\n",
            "                                         'pair',\n",
            "                                         'jazz',\n",
            "                                         'bed',\n",
            "                                         'fuck',\n",
            "                                         'mate',\n",
            "                                         'love',\n",
            "                                         'know',\n",
            "                                         'bang',\n",
            "                                         'couple'],\n",
            "                      'word': 'eff'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'medal',\n",
            "                                        'screenplay',\n",
            "                                        'philadelphia',\n",
            "                                        'legally',\n",
            "                                        'nasa',\n",
            "                                        'win',\n",
            "                                        'street',\n",
            "                                        'define',\n",
            "                                        'assault',\n",
            "                                        'lower'],\n",
            "                      'similar_words': [ 'drugs',\n",
            "                                         'chemical',\n",
            "                                         'experiment',\n",
            "                                         'doctor',\n",
            "                                         'medicine',\n",
            "                                         'company',\n",
            "                                         'industry',\n",
            "                                         'health',\n",
            "                                         'laboratory',\n",
            "                                         'trials'],\n",
            "                      'word': 'pharmacologists'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'leo',\n",
            "                                        'clearly',\n",
            "                                        'basement',\n",
            "                                        'gasoline',\n",
            "                                        'inferior',\n",
            "                                        'wide',\n",
            "                                        'nun',\n",
            "                                        'criminal',\n",
            "                                        'model',\n",
            "                                        'tribe'],\n",
            "                      'similar_words': [ 'anatomy',\n",
            "                                         'figure',\n",
            "                                         'shape',\n",
            "                                         'form',\n",
            "                                         'person',\n",
            "                                         'flesh',\n",
            "                                         'frame',\n",
            "                                         'body',\n",
            "                                         'build',\n",
            "                                         'physical'],\n",
            "                      'word': 'bod'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'text',\n",
            "                                        'registered',\n",
            "                                        'calm',\n",
            "                                        'typically',\n",
            "                                        'statue',\n",
            "                                        'diameter',\n",
            "                                        'vocalist',\n",
            "                                        'athens',\n",
            "                                        'randy',\n",
            "                                        'favour'],\n",
            "                      'similar_words': [ 'let',\n",
            "                                         'allow',\n",
            "                                         'permit',\n",
            "                                         'legitimate',\n",
            "                                         'enact',\n",
            "                                         'license',\n",
            "                                         'statute',\n",
            "                                         'act',\n",
            "                                         'law',\n",
            "                                         'authority'],\n",
            "                      'word': 'legalises'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'bitter',\n",
            "                                        'camp',\n",
            "                                        'memory',\n",
            "                                        'company',\n",
            "                                        'napoleon',\n",
            "                                        'underground',\n",
            "                                        'ask',\n",
            "                                        'constituency',\n",
            "                                        'enforcement',\n",
            "                                        'soap'],\n",
            "                      'similar_words': [ 'meet',\n",
            "                                         'fit',\n",
            "                                         'merit',\n",
            "                                         'advantage',\n",
            "                                         'require',\n",
            "                                         'responsibility',\n",
            "                                         'duty',\n",
            "                                         'suit',\n",
            "                                         'benefit',\n",
            "                                         'serve'],\n",
            "                      'word': 'behoove'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'collecting',\n",
            "                                        'owen',\n",
            "                                        'teammate',\n",
            "                                        'senator',\n",
            "                                        'archipelago',\n",
            "                                        'herbert',\n",
            "                                        'commander',\n",
            "                                        'december',\n",
            "                                        'combination',\n",
            "                                        'painted'],\n",
            "                      'similar_words': [ 'alter',\n",
            "                                         'change',\n",
            "                                         'villain',\n",
            "                                         'attack',\n",
            "                                         'criticism',\n",
            "                                         'abuse',\n",
            "                                         'reputation',\n",
            "                                         'character',\n",
            "                                         'image',\n",
            "                                         'opinion'],\n",
            "                      'word': 'demonise'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'sky',\n",
            "                                        'ant',\n",
            "                                        'partisan',\n",
            "                                        'carol',\n",
            "                                        'craw',\n",
            "                                        'frontier',\n",
            "                                        'warrior',\n",
            "                                        'rough',\n",
            "                                        'dock',\n",
            "                                        'raising'],\n",
            "                      'similar_words': [ 'trade',\n",
            "                                         'interact',\n",
            "                                         'bank',\n",
            "                                         'sell',\n",
            "                                         'deal',\n",
            "                                         'goods',\n",
            "                                         'buy',\n",
            "                                         'machine',\n",
            "                                         'partner',\n",
            "                                         'money'],\n",
            "                      'word': 'transact'},\n",
            "                    { 'frequency_class': 'infrequent',\n",
            "                      'num_senses': 1,\n",
            "                      'polysemy_class': 'monosemous',\n",
            "                      'random_words': [ 'elite',\n",
            "                                        'era',\n",
            "                                        'briefly',\n",
            "                                        'egypt',\n",
            "                                        'cycle',\n",
            "                                        'emphasis',\n",
            "                                        'tale',\n",
            "                                        'names',\n",
            "                                        'swan',\n",
            "                                        'reagan'],\n",
            "                      'similar_words': [ 'regard',\n",
            "                                         'view',\n",
            "                                         'consider',\n",
            "                                         'hold',\n",
            "                                         'see',\n",
            "                                         'rate',\n",
            "                                         'thought',\n",
            "                                         'mind',\n",
            "                                         'believe',\n",
            "                                         'judge'],\n",
            "                      'word': 'deem'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poly_freq = [\"break\", \"cut\", \"running\", \"play\", \"make\", \"better\",\n",
        "             \"light\", \"falls\", \"clear\", \"open\"]\n",
        "\n",
        "poly_infreq = [\"ply\", \"vamp\", \"cant\", \"weares\", \"crams\",\n",
        "               \"cons\", \"mend\", \"spiel\", \"hitch\", \"middles\"]\n",
        "\n",
        "mono_freq = [\"tennis\", \"praised\", \"victory\", \"guild\", \"mini\", \"grossing\",\n",
        "             \"highway\", \"televised\", \"alleged\", \"almost\"]\n",
        "\n",
        "mono_infreq = [\"denouncements\", \"mortgagee\", \"eff\", \"pharmacologists\",\n",
        "               \"bod\", \"legalises\", \"behoove\", \"demonise\", \"transace\", \"deem\"]\n",
        "\n",
        "# target_words_list = set(poly_freq + poly_infreq + mono_freq + mono_infreq)"
      ],
      "metadata": {
        "id": "PljLMoTpkOBC"
      },
      "execution_count": 70,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}